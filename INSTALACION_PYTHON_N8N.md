# ğŸ InstalaciÃ³n de sentence-transformers en n8n

## ğŸ“¦ Requisitos Previos

El nodo Python requiere que **sentence-transformers** estÃ© instalado en el entorno Python de n8n.

## ğŸš€ MÃ©todos de InstalaciÃ³n

### OpciÃ³n 1: Si tienes acceso SSH a tu servidor n8n
```bash
# Conectar al servidor donde corre n8n
ssh tu_usuario@tu_servidor

# Instalar sentence-transformers
pip install sentence-transformers

# O si usas conda
conda install -c conda-forge sentence-transformers
```

### OpciÃ³n 2: Si usas n8n Cloud
```bash
# En n8n Cloud, las dependencias se instalan automÃ¡ticamente
# cuando importas el workflow con el nodo Python
# No necesitas hacer nada adicional
```

### OpciÃ³n 3: Docker de n8n
Si usas n8n en Docker, crea un Dockerfile personalizado:

```dockerfile
FROM n8nio/n8n:latest

# Cambiar a usuario root para instalar dependencias
USER root

# Instalar sentence-transformers
RUN pip install sentence-transformers

# Volver al usuario n8n
USER node
```

## ğŸ”§ VerificaciÃ³n de InstalaciÃ³n

Para verificar que sentence-transformers estÃ¡ correctamente instalado, puedes crear un nodo Python de prueba:

```python
try:
    from sentence_transformers import SentenceTransformer
    print("âœ… sentence-transformers estÃ¡ instalado correctamente")
    
    # Intentar cargar el modelo
    model = SentenceTransformer('all-MiniLM-L6-v2')
    print("âœ… Modelo all-MiniLM-L6-v2 cargado correctamente")
    
    return [{"json": {"status": "success", "model_loaded": True}}]
    
except ImportError as e:
    print(f"âŒ Error: sentence-transformers no estÃ¡ instalado: {e}")
    return [{"json": {"status": "error", "message": str(e)}}]
    
except Exception as e:
    print(f"âŒ Error cargando modelo: {e}")
    return [{"json": {"status": "error", "message": str(e)}}]
```

## ğŸ“ Descarga del Modelo

En la primera ejecuciÃ³n, sentence-transformers descargarÃ¡ automÃ¡ticamente el modelo `all-MiniLM-L6-v2`:

- **TamaÃ±o:** ~90MB
- **UbicaciÃ³n:** `~/.cache/torch/sentence_transformers/`
- **Tiempo:** 1-2 minutos (solo primera vez)

## ğŸƒâ€â™‚ï¸ EjecuciÃ³n del Workflow

Una vez que sentence-transformers estÃ© instalado:

1. **Importa** el workflow actualizado (`plantilla_n8n.json`)
2. **Activa** el workflow
3. **Prueba** enviando una pregunta desde el frontend

El flujo deberÃ­a ser:
```
Pregunta â†’ Embedding Python â†’ BÃºsqueda Pinecone â†’ Respuesta Gemini â†’ Frontend
```

## ğŸ› Troubleshooting

### Error: "No module named 'sentence_transformers'"
```bash
# Verificar quÃ© Python estÃ¡ usando n8n
which python
pip list | grep sentence

# Instalar en el Python correcto
pip install sentence-transformers
```

### Error: "Model download failed"
```bash
# Verificar conexiÃ³n a internet
curl -I https://huggingface.co/

# Limpiar cache si hay problemas
rm -rf ~/.cache/torch/sentence_transformers/
```

### Error: "CUDA out of memory"
```python
# El modelo all-MiniLM-L6-v2 funciona bien en CPU
# No necesitas GPU para este modelo pequeÃ±o
```

## âœ… Checklist de InstalaciÃ³n

- [ ] sentence-transformers instalado en el entorno Python de n8n
- [ ] ConexiÃ³n a internet disponible (para descargar modelo)
- [ ] Workflow importado con el nodo Python actualizado
- [ ] Variables de entorno configuradas (Pinecone, Google Gemini)
- [ ] Workflow activado en n8n

Â¡Listo para usar el sistema RAG con procesamiento 100% local! ğŸ‰