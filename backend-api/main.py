# main.py
# Backend API para el sistema RAG de consultas legales
# Versi√≥n con Vertex AI (Google Cloud)

import os
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from dotenv import load_dotenv

# --- IMPORTS ADICIONALES PARA RAG CON VERTEX AI ---
from google.cloud import aiplatform
from vertexai.language_models import TextEmbeddingModel
from vertexai.generative_models import GenerativeModel
from pinecone import Pinecone
import vertexai

# Cargar las variables de entorno desde .env
load_dotenv()

# --- 1. CONFIGURACI√ìN DE VERTEX AI Y PINECONE ---
PROJECT_ID = os.getenv("GCP_PROJECT_ID", "resolute-return-476416-g5")
REGION = os.getenv("GCP_REGION", "us-central1")
MODEL_NAME = "gemini-2.0-flash-001"  # Modelo de generaci√≥n
EMBEDDING_MODEL = "text-embedding-004"  # Modelo de embeddings de Google

# Configuraci√≥n de Pinecone
PINECONE_API_KEY = os.getenv("PINECONE_API_KEY")
PINECONE_INDEX_NAME = os.getenv("PINECONE_INDEX_NAME", "codigo-penal-vertex-ai")
TOP_K_RESULTS = 20  # Aumentado a 20 para mayor cobertura de art√≠culos largos partidos
TOP_K_MIN = 10  # M√≠nimo para consultas simples
TOP_K_MAX = 30  # M√°ximo para consultas complejas

# --- INICIALIZACI√ìN DE SERVICIOS ---
print("üîß Inicializando Vertex AI y Pinecone...")

# Variables globales para b√∫squeda exacta y cache
TEXTO_COMPLETO_PDF = None
ARTICULOS_CACHE = {}  # Cache: {numero_articulo: texto_completo_articulo}

try:
    # A. Inicializar Vertex AI
    vertexai.init(project=PROJECT_ID, location=REGION)
    print(f"‚úÖ Vertex AI inicializado - Proyecto: {PROJECT_ID}, Regi√≥n: {REGION}")
    
    # B. Inicializar Pinecone
    pc = Pinecone(api_key=PINECONE_API_KEY)
    PINECONE_INDEX = pc.Index(PINECONE_INDEX_NAME)
    print(f"‚úÖ Pinecone conectado - √çndice: {PINECONE_INDEX_NAME}")

    # C. Cargar Modelos de Vertex AI
    EMBEDDING_CLIENT = TextEmbeddingModel.from_pretrained(EMBEDDING_MODEL)
    LLM_CLIENT = GenerativeModel(MODEL_NAME)
    print(f"‚úÖ Modelos cargados - Embeddings: {EMBEDDING_MODEL}, LLM: {MODEL_NAME}")
    
    # D. Cargar texto completo del PDF para b√∫squeda exacta
    try:
        import PyPDF2
        import re
        pdf_path = "../documentos/codigo_penal.pdf"
        with open(pdf_path, 'rb') as file:
            pdf_reader = PyPDF2.PdfReader(file)
            texto_paginas = []
            for page in pdf_reader.pages:
                texto_paginas.append(page.extract_text())
            TEXTO_COMPLETO_PDF = "\n".join(texto_paginas)
            print(f"‚úÖ PDF cargado para b√∫squeda exacta ({len(TEXTO_COMPLETO_PDF)} caracteres)")
            
        # E. Construir cache de art√≠culos para b√∫squeda ultra-r√°pida (‚ö° Mejora #1)
        print("üîÑ Construyendo cache de art√≠culos...")
        
        # Estrategia robusta: encontrar todos los inicios de art√≠culos
        # Patr√≥n que acepta m√∫ltiples variantes: "Art√≠culo", "Articulo", "ART√çCULO", etc.
        patron_inicio = r'Art[i√≠\xed]culo\s+(\d+(?:\s+(?:bis|ter|quater))?)\s*\.?'
        matches = list(re.finditer(patron_inicio, TEXTO_COMPLETO_PDF, re.IGNORECASE))
        
        print(f"   üìã Detectados {len(matches)} inicios de art√≠culos en el PDF")
        
        for i, match in enumerate(matches):
            numero_articulo = match.group(1).strip()
            inicio = match.start()
            
            # Encontrar el final: siguiente art√≠culo o fin del texto
            if i < len(matches) - 1:
                fin = matches[i + 1].start()
            else:
                fin = len(TEXTO_COMPLETO_PDF)
            
            # Extraer texto completo del art√≠culo
            texto_articulo = TEXTO_COMPLETO_PDF[inicio:fin].strip()
            
            # Limpiar saltos de l√≠nea excesivos pero mantener estructura
            texto_articulo = re.sub(r'\n{3,}', '\n\n', texto_articulo)
            
            ARTICULOS_CACHE[numero_articulo] = texto_articulo
        
        print(f"‚úÖ Cache construido: {len(ARTICULOS_CACHE)} art√≠culos indexados para b√∫squeda instant√°nea")
        
        if len(ARTICULOS_CACHE) < 500:
            print(f"‚ö†Ô∏è  ADVERTENCIA: Solo se cachearon {len(ARTICULOS_CACHE)} art√≠culos (esperado ~600+)")
            print(f"   Primeros 10 art√≠culos cacheados: {list(ARTICULOS_CACHE.keys())[:10]}")
            # Mostrar muestra del PDF para debug
            muestra = TEXTO_COMPLETO_PDF[10000:10500]
            print(f"   Muestra del PDF (chars 10000-10500):")
            print(f"   {repr(muestra[:200])}")
        else:
            print(f"‚úÖ Calidad del cache verificada")
            # Verificar algunos art√≠culos clave
            articulos_prueba = ['138', '237', '244', '142']
            encontrados = [art for art in articulos_prueba if art in ARTICULOS_CACHE]
            print(f"   Art√≠culos de prueba ({len(encontrados)}/4): {encontrados}")
        
    except Exception as e:
        print(f"‚ö†Ô∏è No se pudo cargar PDF completo: {e} (b√∫squeda exacta deshabilitada)")
    
    print("‚úÖ ¬°Inicializaci√≥n completada con √©xito!")

except Exception as e:
    print(f"‚ùå ERROR DE INICIALIZACI√ìN: {e}")
    raise


# --- 2. MODELOS DE DATOS ---
class ChatMessage(BaseModel):
    """Modelo para un mensaje en el historial de conversaci√≥n"""
    role: str  # "user" o "assistant"
    content: str


class ChatRequest(BaseModel):
    pregunta: str
    historial: list[ChatMessage] = []  # ‚ö° MEJORA #3: Historial conversacional


class ChatResponse(BaseModel):
    respuesta: str
    metadata: dict = None


# --- 3. INICIALIZAR LA APLICACI√ìN ---
app = FastAPI(
    title="API RAG - C√≥digo Penal Espa√±ol",
    description="API para consultas sobre el C√≥digo Penal usando RAG",
    version="1.0.0"
)

# Configurar CORS para permitir peticiones desde el frontend
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # En producci√≥n, especifica tu dominio exacto
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


# --- 4. FUNCI√ìN CENTRAL DE RAG CON VERTEX AI ---

def buscar_articulo_exacto(texto_completo: str, numero_articulo: str) -> str:
    """
    Busca un art√≠culo espec√≠fico usando cache O(1) o fallback a regex O(n).
    Soporta art√≠culos simples (142) y con sufijos (142 bis, 127 ter, etc.)
    
    ‚ö° MEJORA #1: B√∫squeda instant√°nea desde cache construido al inicio
    """
    import re
    
    # Normalizar el n√∫mero de art√≠culo
    numero_articulo = numero_articulo.strip()
    
    # ‚ö° PASO 1: Buscar en cache primero (O(1) - instant√°neo)
    if numero_articulo in ARTICULOS_CACHE:
        print(f"‚ö° Art√≠culo {numero_articulo} encontrado en cache (b√∫squeda instant√°nea)")
        return ARTICULOS_CACHE[numero_articulo]
    
    # PASO 2: Si no est√° en cache, buscar con regex (O(n) - lento)
    print(f"üîç Art√≠culo {numero_articulo} no en cache, buscando con regex...")
    
    # Si tiene bis/ter/quater, buscar exactamente ese art√≠culo
    if re.search(r'\b(bis|ter|quater)\b', numero_articulo, re.IGNORECASE):
        # Buscar "Art√≠culo 127 bis" espec√≠ficamente
        pattern = rf"(?i)(art[√≠i]culo\s+{re.escape(numero_articulo)})[\.\s]+(.+?)(?=\n\s*Art[√≠i]culo\s+\d+|\Z)"
    else:
        # Buscar "Art√≠culo N" pero NO "Art√≠culo N bis/ter/quater"
        pattern = rf"(?i)(art[√≠i]culo\s+{numero_articulo})\s+(?!bis|ter|quater)(.+?)(?=\n\s*Art[√≠i]culo\s+\d+\s|\Z)"
    
    match = re.search(pattern, texto_completo, re.DOTALL | re.IGNORECASE)
    
    if match:
        # Incluir el encabezado completo "Art√≠culo N"
        texto_articulo = match.group(0).strip()
        
        # Guardar en cache para futuras b√∫squedas
        ARTICULOS_CACHE[numero_articulo] = texto_articulo
        print(f"üíæ Art√≠culo {numero_articulo} guardado en cache")
        
        # NO truncar - devolver el art√≠culo completo
        return texto_articulo
    
    return None


def corregir_encoding(texto: str) -> str:
    """
    Corrige problemas de encoding usando ftfy (autom√°tico y robusto).
    
    ‚ö° MEJORA #2: Correcci√≥n autom√°tica con ftfy en lugar de reemplazos manuales
    """
    try:
        import ftfy
        # ftfy detecta y corrige autom√°ticamente problemas de encoding
        texto_corregido = ftfy.fix_text(texto)
        return texto_corregido
    except ImportError:
        # Fallback a reemplazos manuales si ftfy no est√° disponible
        texto = texto.replace('√É¬≠', '√≠')
        texto = texto.replace('√É¬≥', '√≥')
        texto = texto.replace('√É¬±', '√±')
        texto = texto.replace('√É¬°', '√°')
        texto = texto.replace('√É¬©', '√©')
        texto = texto.replace('√É¬∫', '√∫')
        texto = texto.replace('√É¬º', '√º')
        texto = texto.replace('√É¬∂', '√∂')
        
        # May√∫sculas
        texto = texto.replace('√É', '√Å')
        texto = texto.replace('√É‚Ä∞', '√â')
        texto = texto.replace('√É"', '√ì')
        texto = texto.replace('√É≈°', '√ö')
        
        # Eliminar caracteres basura
        texto = texto.replace('√Ç', '')
        
        return texto


def detectar_articulos_en_chunks(chunks: list) -> dict:
    """
    Analiza chunks recuperados y detecta qu√© art√≠culos aparecen y cu√°ntas partes tienen.
    Retorna: {numero_articulo: [lista de chunks con ese art√≠culo]}
    """
    import re
    articulos_encontrados = {}
    
    for idx, chunk in enumerate(chunks):
        texto = chunk.get('metadata', {}).get('text', '')
        
        # Buscar todos los art√≠culos mencionados en este chunk
        matches = re.finditer(r'Art[√≠i]culo\s+(\d+(?:\s+bis|\s+ter|\s+quater)?)', texto, re.IGNORECASE)
        
        for match in matches:
            num_articulo = match.group(1).strip()
            
            if num_articulo not in articulos_encontrados:
                articulos_encontrados[num_articulo] = []
            
            articulos_encontrados[num_articulo].append({
                'chunk_index': idx,
                'score': chunk.get('score', 0),
                'texto': texto,
                'posicion_articulo': match.start()
            })
    
    return articulos_encontrados


def es_articulo_incompleto(texto: str) -> bool:
    """
    Detecta si un chunk contiene un art√≠culo incompleto.
    Heur√≠sticas:
    - Termina abruptamente (no termina en punto)
    - Contiene "..." o texto cortado
    - Tiene numeraci√≥n incompleta (1., 2., pero no cierra)
    """
    import re
    
    texto_limpio = texto.strip()
    
    # Heur√≠stica 1: No termina en punto ni en par√©ntesis de cierre
    if not texto_limpio.endswith(('.', ')', '¬ª', '"')):
        return True
    
    # Heur√≠stica 2: Contiene indicadores de truncado
    if '...' in texto_limpio or '[truncado]' in texto_limpio.lower():
        return True
    
    # Heur√≠stica 3: Tiene numeraci√≥n sin cerrar (ej: "1. xxx 2. xxx 3." pero sin texto despu√©s del 3)
    numeros = re.findall(r'\n\s*(\d+)\.\s+', texto_limpio)
    if len(numeros) >= 2:
        ultimo_numero = numeros[-1]
        # Verificar si despu√©s del √∫ltimo n√∫mero hay texto sustancial
        patron = rf'{ultimo_numero}\.\s+(.+)$'
        match = re.search(patron, texto_limpio, re.DOTALL)
        if match and len(match.group(1).strip()) < 20:
            return True
    
    return False


def reconstruir_articulos_completos(articulos_detectados: dict, chunks_originales: list) -> dict:
    """
    Para art√≠culos que aparecen partidos, intenta reconstruirlos usando:
    1. Combinaci√≥n de m√∫ltiples chunks si est√°n disponibles
    2. B√∫squeda instant√°nea en ARTICULOS_CACHE (O(1))
    
    Retorna: {numero_articulo: texto_completo_reconstruido}
    """
    articulos_reconstruidos = {}
    
    for num_articulo, partes in articulos_detectados.items():
        # Ordenar partes por posici√≥n en el texto (usando chunk_index como proxy)
        partes_ordenadas = sorted(partes, key=lambda x: x['chunk_index'])
        
        # CASO 1: Solo hay 1 parte
        if len(partes_ordenadas) == 1:
            texto = partes_ordenadas[0]['texto']
            
            # Verificar si parece incompleto
            if es_articulo_incompleto(texto):
                print(f"  ‚ö†Ô∏è Art. {num_articulo} parece incompleto (1 chunk) - buscando en cache...")
                
                # ‚ö° MEJORA #1: B√∫squeda instant√°nea en cache O(1)
                if num_articulo in ARTICULOS_CACHE:
                    articulo_completo = ARTICULOS_CACHE[num_articulo]
                    articulos_reconstruidos[num_articulo] = {
                        'texto': corregir_encoding(articulo_completo),
                        'metodo': 'cache_instantaneo',
                        'completo': True
                    }
                    print(f"  ‚úÖ Art. {num_articulo} reconstruido desde cache (O(1))")
                    continue
                
                # Si no se pudo reconstruir, usar lo que hay pero marcarlo como incompleto
                articulos_reconstruidos[num_articulo] = {
                    'texto': corregir_encoding(texto),
                    'metodo': 'chunk_unico',
                    'completo': False
                }
            else:
                # Parece completo
                articulos_reconstruidos[num_articulo] = {
                    'texto': corregir_encoding(texto),
                    'metodo': 'chunk_unico',
                    'completo': True
                }
        
        # CASO 2: M√∫ltiples partes - intentar combinarlas
        else:
            print(f"  üîÑ Art. {num_articulo} encontrado en {len(partes_ordenadas)} chunks - combinando...")
            
            # Combinar textos evitando duplicados
            textos_combinados = []
            texto_previo = ""
            
            for parte in partes_ordenadas:
                texto_actual = parte['texto']
                
                # Evitar duplicar texto si hay overlap
                if texto_previo:
                    # Buscar overlap entre final de texto_previo y inicio de texto_actual
                    overlap_length = min(200, len(texto_previo), len(texto_actual))
                    for i in range(overlap_length, 0, -1):
                        if texto_previo[-i:] == texto_actual[:i]:
                            texto_actual = texto_actual[i:]
                            break
                
                textos_combinados.append(texto_actual)
                texto_previo = texto_actual
            
            texto_combinado = "".join(textos_combinados)
            
            # Verificar si la combinaci√≥n parece completa
            if es_articulo_incompleto(texto_combinado):
                print(f"  ‚ö†Ô∏è Art. {num_articulo} combinado a√∫n parece incompleto - buscando en cache...")
                
                # ‚ö° MEJORA #1: Fallback a b√∫squeda instant√°nea en cache
                if num_articulo in ARTICULOS_CACHE:
                    articulo_completo = ARTICULOS_CACHE[num_articulo]
                    articulos_reconstruidos[num_articulo] = {
                        'texto': corregir_encoding(articulo_completo),
                        'metodo': 'cache_instantaneo_fallback',
                        'completo': True
                    }
                    print(f"  ‚úÖ Art. {num_articulo} reconstruido desde cache (O(1) fallback)")
                    continue
            
            articulos_reconstruidos[num_articulo] = {
                'texto': corregir_encoding(texto_combinado),
                'metodo': f'combinacion_{len(partes_ordenadas)}_chunks',
                'completo': not es_articulo_incompleto(texto_combinado)
            }
    
    return articulos_reconstruidos


def decidir_estrategia_busqueda(query: str, numero_articulo: str = None) -> dict:
    """
    Decide din√°micamente qu√© estrategia de b√∫squeda usar bas√°ndose en la consulta.
    
    Retorna:
    {
        'top_k': int,  # Cu√°ntos resultados recuperar
        'usar_reconstruccion': bool,  # Si aplicar post-procesamiento
        'razon': str  # Explicaci√≥n de la decisi√≥n
    }
    """
    import re
    
    # ESTRATEGIA 1: Consulta de art√≠culo espec√≠fico simple
    if numero_articulo and not re.search(r'\b(y|o|con|sin|adem√°s|tambi√©n)\b', query, re.IGNORECASE):
        return {
            'top_k': TOP_K_MIN,  # 10 suficiente, ir√° a b√∫squeda exacta
            'usar_reconstruccion': False,
            'razon': 'Consulta de art√≠culo espec√≠fico - b√∫squeda exacta'
        }
    
    # ESTRATEGIA 2: Consulta compleja con m√∫ltiples conceptos
    palabras = query.split()
    tiene_conectores = bool(re.search(r'\b(y|o|adem√°s|tambi√©n|con|m√°s)\b', query, re.IGNORECASE))
    
    if len(palabras) > 8 or tiene_conectores:
        return {
            'top_k': TOP_K_MAX,  # 30 para capturar m√°s contexto
            'usar_reconstruccion': True,
            'razon': 'Consulta compleja multi-concepto - m√°xima cobertura + reconstrucci√≥n'
        }
    
    # ESTRATEGIA 3: Consulta conceptual media (default)
    return {
        'top_k': TOP_K_RESULTS,  # 20 (balance)
        'usar_reconstruccion': True,
        'razon': 'Consulta conceptual est√°ndar - cobertura media + reconstrucci√≥n'
    }


def generate_rag_response(query: str, historial: list = None):
    """
    Sistema RAG h√≠brido con b√∫squeda exacta + vector search + memoria conversacional.
    
    ‚ö° MEJORA #3: Soporte para historial conversacional
    
    1. Enriquece la consulta con contexto del historial (si aplica)
    2. Detecta si es consulta de art√≠culo espec√≠fico
    3. Intenta b√∫squeda exacta con regex primero
    4. Si no encuentra, usa RAG con embeddings
    5. Corrige encoding en todos los resultados
    """
    import re  # Importar al principio para usar en todo el scope
    import time  # Para medir tiempo de respuesta
    
    start_time = time.time()  # Iniciar contador de tiempo
    
    try:
        print(f"\n{'='*80}")
        print(f"üì® CONSULTA: {query}")
        if historial:
            print(f"üí¨ Historial: {len(historial)} mensajes previos")
        print(f"{'='*80}")

        # --- PASO 0.5: ENRIQUECER CONSULTA CON CONTEXTO CONVERSACIONAL ---
        query_enriquecida = query
        nota_correccion = ""  # Variable para almacenar instrucciones de correcci√≥n
        
        if historial and len(historial) > 0:
            print(f"üîç DEBUG: Analizando si es consulta de seguimiento...")
            
            # Detectar si es una consulta de seguimiento
            palabras_seguimiento = ['y', 'tambi√©n', 'adem√°s', 'qu√© m√°s', 'otra', 'ese', 'esa', 'esos', 'esas', 'cu√°l', 'pena', 'entonces', 'pero']
            
            # Palabras que indican nuevo caso (resetear contexto)
            palabras_nuevo_caso = ['nuevo caso', 'otra consulta', 'ahora sobre', 'pregunta nueva', 'cambio de tema']
            
            # Palabras que indican correcci√≥n/refinamiento
            palabras_correccion = ['no', 'mejor', 'prefiero', 'creo que', 'en realidad', 'deber√≠a ser', 
                                  'en vez de', 'en lugar de', 'm√°s bien', 'correcci√≥n', 'correci√≥n',
                                  'no es', 'ser√≠a mejor', 'm√°s apropiado', 'en su lugar']
            
            query_lower = query.lower().strip()
            print(f"   Query lowercase: '{query_lower}'")
            print(f"   N√∫mero de palabras: {len(query.split())}")
            
            # Si menciona expl√≠citamente nuevo caso, no enriquecer
            es_nuevo_caso = any(palabra in query_lower for palabra in palabras_nuevo_caso)
            print(f"   Es nuevo caso: {es_nuevo_caso}")
            
            # Detectar si menciona art√≠culo
            menciona_articulo = bool(re.search(r'\b(?:art[√≠i]culo|art\.?)\s*\d+', query, re.IGNORECASE))
            print(f"   Menciona art√≠culo: {menciona_articulo}")
            
            # PRIORIDAD 1: Detectar si es correcci√≥n/refinamiento
            es_correccion = any(palabra in query_lower for palabra in palabras_correccion) and menciona_articulo
            print(f"   Es correcci√≥n: {es_correccion}")
            
            if es_correccion:
                print(f"üîÑ CORRECCI√ìN DETECTADA - Usuario propone art√≠culo alternativo")
                
                # Extraer el art√≠culo propuesto
                match_articulo_propuesto = re.search(r'art[√≠i]culo\s*(\d+(?:\s+(?:bis|ter|quater))?)', query, re.IGNORECASE)
                if match_articulo_propuesto:
                    articulo_propuesto = match_articulo_propuesto.group(1).strip()
                    print(f"   üìå Art√≠culo propuesto por usuario: {articulo_propuesto}")
                    
                    # Obtener contexto de qu√© art√≠culos se mencionaron antes
                    articulos_previos = []
                    for msg in reversed(historial):
                        if msg.role == "assistant":
                            # Buscar art√≠culos mencionados en la respuesta anterior
                            matches_previos = re.finditer(r'Art[√≠i]culo\s*(\d+)', msg.content, re.IGNORECASE)
                            articulos_previos = [m.group(1) for m in matches_previos]
                            if articulos_previos:
                                print(f"   üìã Art√≠culos en respuesta anterior: {articulos_previos[:3]}")
                                break
                    
                    # Crear nota de correcci√≥n para Gemini
                    nota_correccion = f"""
**üîÑ CORRECCI√ìN/REFINAMIENTO DEL USUARIO:**
El usuario est√° sugiriendo que el **art√≠culo {articulo_propuesto}** ser√≠a m√°s apropiado.

**‚ö†Ô∏è IMPORTANTE - NO ACEPTES AUTOM√ÅTICAMENTE:**
El usuario puede estar equivocado. Debes EVALUAR primero si su sugerencia es correcta.

**PASO 1 - EVALUAR OBLIGATORIAMENTE:**
Antes de responder, analiza cr√≠ticamente:

1. **Hechos del caso original:** {historial[0].content if historial else "N/A"}
2. **Art√≠culos previamente identificados como correctos:** {articulos_previos[:3] if articulos_previos else "N/A"}
3. **Art√≠culo propuesto por el usuario:** {articulo_propuesto}

**PREG√öNTATE:**
- ¬øEl art√≠culo {articulo_propuesto} realmente encaja con los HECHOS descritos en el caso?
- ¬øLos requisitos legales del art√≠culo {articulo_propuesto} se cumplen en este caso?
- ¬øO el usuario est√° confundiendo conceptos? (ejemplo: doloso vs imprudente, fuerza vs intimidaci√≥n)

**PASO 2 - RESPONDER SEG√öN TU EVALUACI√ìN:**

**OPCI√ìN A - SI EL ART√çCULO {articulo_propuesto} ES CORRECTO:**
‚úÖ El usuario tiene raz√≥n ‚Üí Responde:
"Tienes raz√≥n, el art√≠culo {articulo_propuesto} [nombre del delito] es el m√°s apropiado porque [breve raz√≥n]."
Luego proporciona ficha legal completa del art√≠culo {articulo_propuesto}.

**OPCI√ìN B - SI EL ART√çCULO {articulo_propuesto} NO ES CORRECTO:**
‚ùå El usuario se equivoca ‚Üí Responde:
"Entiendo que sugieres el art√≠culo {articulo_propuesto} ([nombre del delito que propone]), sin embargo, este art√≠culo no ser√≠a el m√°s apropiado para este caso porque [raz√≥n espec√≠fica: qu√© requisito NO se cumple].

Seg√∫n los hechos descritos [mencionar hechos relevantes], el art√≠culo correcto ser√≠a el **art√≠culo [X]** ([nombre del delito correcto]) porque [raz√≥n espec√≠fica: qu√© requisito S√ç se cumple].

A continuaci√≥n te muestro ambos art√≠culos para que puedas comparar:

[Muestra AMBOS art√≠culos con sus diferencias clave resaltadas]"

**EJEMPLOS DE CORRECCI√ìN:**

‚úÖ **Ejemplo cuando usuario ACIERTA:**
Usuario sugiere: art. 237 en caso de robo con fuerza
Respuesta: "Tienes raz√≥n, el art√≠culo 237 sobre robo con fuerza en las cosas es el apropiado porque los hechos indican escalamiento..."

‚ùå **Ejemplo cuando usuario SE EQUIVOCA:**
Usuario sugiere: art. 138 (homicidio doloso) en caso de atropello imprudente
Respuesta: "Entiendo que sugieres el art√≠culo 138 (homicidio doloso), sin embargo, este art√≠culo requiere que la muerte se cause con **intenci√≥n deliberada**, lo cual no se cumple en un atropello por imprudencia.

Seg√∫n los hechos descritos (atropello por imprudencia grave), el art√≠culo correcto ser√≠a el **art√≠culo 142** (homicidio imprudente) porque..."

**NO ASUMAS QUE EL USUARIO SIEMPRE TIENE RAZ√ìN. EVAL√öA CR√çTICAMENTE.**
"""
                    
                    # No enriquecer con contexto previo en correcciones - el usuario ya sabe qu√© quiere
                    query_enriquecida = query
                    print(f"   ‚úÖ Correcci√≥n procesada - enfoc√°ndose en art√≠culo {articulo_propuesto}")
                
            elif es_nuevo_caso:
                print(f"üÜï Nuevo caso detectado - no se enriquece con historial")
            else:
                # Criterios para considerar seguimiento:
                # 1. Empieza con palabra de seguimiento (muy com√∫n)
                # 2. Es una consulta corta (< 10 palabras) con palabra de seguimiento
                # 3. No menciona expl√≠citamente un art√≠culo nuevo
                
                empieza_con_seguimiento = any(query_lower.startswith(palabra) for palabra in palabras_seguimiento)
                contiene_seguimiento = any(palabra in query_lower for palabra in palabras_seguimiento)
                es_corta = len(query.split()) < 10
                
                print(f"   Empieza con seguimiento: {empieza_con_seguimiento}")
                print(f"   Contiene seguimiento: {contiene_seguimiento}")
                print(f"   Es corta (<10 palabras): {es_corta}")
                
                # No es seguimiento si menciona expl√≠citamente un art√≠culo
                menciona_articulo = bool(re.search(r'\b(?:art[√≠i]culo|art\.?)\s*\d+', query, re.IGNORECASE))
                print(f"   Menciona art√≠culo: {menciona_articulo}")
                
                es_seguimiento = (empieza_con_seguimiento or (contiene_seguimiento and es_corta)) and not menciona_articulo
                print(f"   ‚úÖ RESULTADO: Es seguimiento = {es_seguimiento}")
                
                if es_seguimiento:
                    # Tomar el √∫ltimo contexto del usuario para entender el tema
                    contexto_previo = ""
                    
                    print(f"   üîç Buscando contexto previo en historial ({len(historial)} mensajes)...")
                    # Buscar en historial la √∫ltima pregunta del usuario (no la respuesta del bot)
                    for i, msg in enumerate(reversed(historial)):
                        print(f"      Mensaje {i}: role='{msg.role}', content='{msg.content[:50]}...'")
                        if msg.role == "user":
                            contexto_previo = msg.content
                            print(f"      ‚úì Contexto encontrado!")
                            break
                    
                    if contexto_previo:
                        query_enriquecida = f"{contexto_previo} {query}"
                        print(f"üîó Consulta detectada como seguimiento")
                        print(f"üìù Contexto previo: {contexto_previo[:80]}...")
                        print(f"üîç Consulta enriquecida: {query_enriquecida[:150]}...")
                    else:
                        print(f"‚ö†Ô∏è Seguimiento detectado pero sin contexto previo")
                else:
                    print(f"   ‚ÑπÔ∏è  No se detect√≥ como seguimiento - usando consulta original")

        # --- PASO 1: DETECTAR N√öMERO DE ART√çCULO O RANGO ---
        articulo_pattern = r'\b(?:art[√≠i]culo|art\.?)\s*(\d+(?:\s+bis|\s+ter|\s+quater)?)\b'
        solo_numero_pattern = r'^\s*(\d+(?:\s+bis|\s+ter|\s+quater)?)\s*$'
        
        # üÜï MEJORA #4: Detectar rangos de art√≠culos (ej: "art√≠culos 138 a 142", "del 237 al 244")
        rango_pattern_1 = r'\b(?:art[√≠i]culos?|arts?\.?)\s*(\d+)\s*(?:a|al|hasta|-)\s*(?:art[√≠i]culo|art\.?)?\s*(\d+)\b'
        rango_pattern_2 = r'\b(?:del|desde)\s*(?:art[√≠i]culo|art\.?)?\s*(\d+)\s*(?:a|al|hasta)\s*(?:art[√≠i]culo|art\.?)?\s*(\d+)\b'
        rango_pattern_3 = r'\b(\d+)\s*(?:a|al|-)\s*(\d+)\s*$'  # Solo n√∫meros al final
        
        numero_articulo = None
        rango_articulos = None
        
        # Primero verificar si es un rango
        match_rango = (re.search(rango_pattern_1, query_enriquecida, re.IGNORECASE) or 
                       re.search(rango_pattern_2, query_enriquecida, re.IGNORECASE) or
                       re.search(rango_pattern_3, query_enriquecida, re.IGNORECASE))
        
        if match_rango:
            inicio = int(match_rango.group(1))
            fin = int(match_rango.group(2))
            
            # Validar que el rango sea razonable (m√°ximo 20 art√≠culos)
            if inicio < fin and (fin - inicio) <= 20:
                rango_articulos = (inicio, fin)
                print(f"üìö Rango de art√≠culos detectado: {inicio} a {fin} ({fin - inicio + 1} art√≠culos)")
            else:
                print(f"‚ö†Ô∏è Rango inv√°lido o demasiado amplio: {inicio} a {fin}")
        
        # Si no hay rango, buscar art√≠culo individual
        if not rango_articulos:
            match_articulo = re.search(articulo_pattern, query_enriquecida, re.IGNORECASE)
            match_numero = re.match(solo_numero_pattern, query_enriquecida)
            
            if match_articulo:
                numero_articulo = match_articulo.group(1)
                print(f"üéØ Art√≠culo detectado (patr√≥n completo): {numero_articulo}")
            elif match_numero:
                numero_articulo = match_numero.group(1)
                print(f"üéØ Art√≠culo detectado (solo n√∫mero): {numero_articulo}")
            else:
                print(f"‚ÑπÔ∏è  No se detect√≥ n√∫mero de art√≠culo en la query")
        
        # --- PASO 2: B√öSQUEDA EXACTA INSTANT√ÅNEA ---
        # ‚ö° MEJORA #1: Usar cache O(1) para art√≠culos individuales
        # üìö MEJORA #4: Usar cache para rangos de art√≠culos
        # EXCEPCI√ìN: Si es una correcci√≥n, NO usar cache directo - pasar por Gemini con contexto
        
        # üìö Caso 1: RANGO DE ART√çCULOS
        if rango_articulos:
            inicio, fin = rango_articulos
            articulos_encontrados = []
            articulos_faltantes = []
            articulos_incompletos = []
            
            print(f"üìö Buscando rango de art√≠culos {inicio} a {fin} en cache...")
            
            for num in range(inicio, fin + 1):
                num_str = str(num)
                if num_str in ARTICULOS_CACHE:
                    texto = ARTICULOS_CACHE[num_str]
                    
                    # üîç Verificar si el art√≠culo est√° completo
                    if es_articulo_incompleto(texto):
                        print(f"   ‚ö†Ô∏è Art. {num_str} est√° incompleto en cache")
                        articulos_incompletos.append(num_str)
                    else:
                        articulos_encontrados.append((num_str, texto))
                else:
                    articulos_faltantes.append(num_str)
            
            print(f"‚úÖ Completos: {len(articulos_encontrados)}/{fin - inicio + 1} art√≠culos")
            if articulos_faltantes:
                print(f"‚ö†Ô∏è No encontrados: {articulos_faltantes}")
            if articulos_incompletos:
                print(f"‚ö†Ô∏è Incompletos (pasar√°n por RAG): {articulos_incompletos}")
            
            # Si hay art√≠culos incompletos, NO usar cache directo - pasar por RAG
            if articulos_incompletos:
                print(f"üîÑ Rango contiene {len(articulos_incompletos)} art√≠culo(s) incompleto(s) - usando RAG para reconstruir")
                # NO retornar aqu√≠ - dejar que caiga en el flujo de RAG normal
            elif articulos_encontrados:
                # Solo si TODOS los art√≠culos est√°n completos, responder desde cache
                respuesta_rango = f"**Art√≠culos {inicio} a {fin} del C√≥digo Penal**\n\n"
                
                for num, texto in articulos_encontrados:
                    texto_corregido = corregir_encoding(texto)
                    respuesta_rango += f"**Art√≠culo {num}**\n\n{texto_corregido}\n\n{'='*70}\n\n"
                
                if articulos_faltantes:
                    respuesta_rango += f"\n‚ö†Ô∏è **Nota:** Los siguientes art√≠culos no se encontraron en la base de datos: {', '.join(articulos_faltantes)}"
                
                print(f"‚ö° Respuesta de rango generada ({len(respuesta_rango)} caracteres)")
                return {
                    "respuesta": respuesta_rango,
                    "metadata": {
                        "num_fragmentos": len(articulos_encontrados),
                        "tiene_contexto": True,
                        "modelo": "Cache instant√°neo - Rango",
                        "embedding_model": "N/A",
                        "metodo": "cache_rango",
                        "fuentes": [f"Art√≠culo {num}" for num, _ in articulos_encontrados],
                        "tiempo_respuesta": time.time() - start_time
                    }
                }
        
        # üéØ Caso 2: ART√çCULO INDIVIDUAL
        if numero_articulo:
            print(f"üîë Buscando '{numero_articulo}' en cache...")
            print(f"üìã Cache tiene {len(ARTICULOS_CACHE)} art√≠culos")
            print(f"üîç Art√≠culo en cache: {numero_articulo in ARTICULOS_CACHE}")
            
        # Solo usar cache directo si NO es correcci√≥n
        if numero_articulo and numero_articulo in ARTICULOS_CACHE and not nota_correccion:
            print(f"‚ö° B√∫squeda instant√°nea en cache para art√≠culo {numero_articulo}...")
            texto_exacto = ARTICULOS_CACHE[numero_articulo]
            
            if texto_exacto:
                print(f"‚úÖ ¬°Art√≠culo {numero_articulo} encontrado en cache (O(1))!")
                
                # üîç Verificar si el art√≠culo en cache est√° completo
                if es_articulo_incompleto(texto_exacto):
                    print(f"‚ö†Ô∏è  Art√≠culo {numero_articulo} en cache parece INCOMPLETO - pasando por RAG para reconstrucci√≥n...")
                    # NO retornar aqu√≠ - dejar que caiga en el flujo de RAG normal
                else:
                    texto_corregido = corregir_encoding(texto_exacto)
                    
                    # Responder directamente sin pasar por Gemini si es texto razonable
                    # Aumentado a 4000 caracteres (la mayor√≠a de art√≠culos caben)
                    if len(texto_corregido) < 4000:
                        respuesta_final = f"**Art√≠culo {numero_articulo}**\n\n{texto_corregido}"
                        return {
                            "respuesta": respuesta_final,
                            "metadata": {
                                "num_fragmentos": 1,
                                "tiene_contexto": True,
                                "modelo": "Cache instant√°neo (sin LLM)",
                                "embedding_model": "N/A",
                                "metodo": "cache_O(1)"
                            }
                        }
                    else:
                        # Si es muy largo (>4000 chars), pasar por Gemini para formatear mejor
                        prompt = f"""Eres un asistente legal especializado en el C√≥digo Penal espa√±ol.

El usuario pregunt√≥: "{query}"

Aqu√≠ est√° el texto LITERAL y COMPLETO del art√≠culo encontrado:

{texto_corregido}

INSTRUCCIONES:
1. Responde con el texto COMPLETO del art√≠culo tal como aparece
2. NO resumas ni parafrasees - cita el texto literal
3. Organiza el contenido de forma clara usando formato Markdown
4. Mant√©n TODOS los apartados, n√∫meros y subapartados
5. Usa el formato: **Art√≠culo [n√∫mero].** seguido del texto completo

Responde ahora:"""

                        response = LLM_CLIENT.generate_content(prompt)
                        return {
                            "respuesta": response.text,
                            "metadata": {
                                "num_fragmentos": 1,
                                "tiene_contexto": True,
                                "modelo": MODEL_NAME,
                                "embedding_model": "N/A",
                                "metodo": "exact_match_formatted"
                            }
                        }

        # --- PASO 3: DECIDIR ESTRATEGIA INTELIGENTE ---
        estrategia = decidir_estrategia_busqueda(query, numero_articulo)
        print(f"üß† Estrategia seleccionada: {estrategia['razon']}")
        print(f"   - Top K: {estrategia['top_k']}")
        print(f"   - Reconstrucci√≥n: {estrategia['usar_reconstruccion']}")
        
        # --- PASO 4: ENRIQUECER QUERY (si no hubo match exacto) ---
        if numero_articulo:
            query_enriquecida_embedding = (
                f"Contenido literal del C√≥digo Penal espa√±ol "
                f"Art√≠culo {numero_articulo} delito pena castigo texto completo"
            )
            print(f"üîÑ Query para embedding: {query_enriquecida_embedding}")
        else:
            # IMPORTANTE: Mantener la query enriquecida con contexto conversacional
            # que se cre√≥ en PASO 0.5 (no sobrescribir)
            query_enriquecida_embedding = query_enriquecida
            if query_enriquecida != query:
                print(f"üîÑ Usando query enriquecida con contexto conversacional")

        # --- PASO 5: GENERAR EMBEDDING ---
        print("üî¢ Generando embedding con Vertex AI...")
        embeddings = EMBEDDING_CLIENT.get_embeddings([query_enriquecida_embedding])
        query_vector = embeddings[0].values
        print(f"‚úÖ Embedding generado: {len(query_vector)} dimensiones")

        # --- PASO 6: B√öSQUEDA VECTORIAL EN PINECONE (con Top K din√°mico) ---
        top_k_dinamico = estrategia['top_k']
        print(f"üîç Buscando en Pinecone (TOP_K={top_k_dinamico})...")
        results = PINECONE_INDEX.query(
            vector=query_vector,
            top_k=top_k_dinamico,
            include_metadata=True
        )
        # --- PASO 6: B√öSQUEDA VECTORIAL EN PINECONE (con Top K din√°mico) ---
        top_k_dinamico = estrategia['top_k']
        print(f"üîç Buscando en Pinecone (TOP_K={top_k_dinamico})...")
        results = PINECONE_INDEX.query(
            vector=query_vector,
            top_k=top_k_dinamico,
            include_metadata=True
        )

        # --- PASO 7: FILTRADO ADAPTATIVO ---
        umbral = 0.35 if numero_articulo else 0.45
        print(f"üìä Aplicando umbral adaptativo: {umbral}")
        
        chunks_relevantes = []
        for match in results['matches']:
            score = match.get('score', 0)
            print(f"  üìä Match con score: {score:.3f}")
            
            if score > umbral:
                chunks_relevantes.append(match)
                print(f"  ‚úì Chunk aceptado (score: {score:.3f})")

        if not chunks_relevantes:
            print("‚ö†Ô∏è No hay resultados relevantes despu√©s del filtrado")
            return {
                "respuesta": "Lo siento, no encontr√© informaci√≥n relevante en el C√≥digo Penal sobre tu consulta. ¬øPodr√≠as reformularla o ser m√°s espec√≠fico?",
                "metadata": {
                    "num_fragmentos": 0,
                    "tiene_contexto": False,
                    "modelo": MODEL_NAME,
                    "embedding_model": EMBEDDING_MODEL,
                    "metodo": "rag_vector_search"
                }
            }

        # --- PASO 8: POST-PROCESAMIENTO INTELIGENTE (si est√° habilitado) ---
        if estrategia['usar_reconstruccion']:
            print(f"\nüîß Aplicando reconstrucci√≥n inteligente de art√≠culos...")
            
            # Detectar art√≠culos en los chunks
            articulos_detectados = detectar_articulos_en_chunks(chunks_relevantes)
            print(f"üìã Art√≠culos detectados: {list(articulos_detectados.keys())}")
            
            # Reconstruir art√≠culos completos
            articulos_reconstruidos = reconstruir_articulos_completos(articulos_detectados, chunks_relevantes)
            
            # Construir contexto usando art√≠culos reconstruidos + chunks originales
            contexto_parts = []
            articulos_ya_incluidos = set()
            
            # Primero, agregar art√≠culos reconstruidos
            for num_art, info in articulos_reconstruidos.items():
                if info['completo'] or info['metodo'].startswith('busqueda_exacta'):
                    contexto_parts.append(
                        f"[Art√≠culo {num_art} - Reconstruido ({info['metodo']})]"
                        f"\n{info['texto']}"
                    )
                    articulos_ya_incluidos.add(num_art)
                    print(f"  ‚úÖ Art. {num_art} agregado como reconstruido ({info['metodo']})")
            
            # Luego, agregar chunks que no sean de art√≠culos ya reconstruidos
            for match in chunks_relevantes:
                texto = match.get('metadata', {}).get('text', '')
                score = match.get('score', 0)
                
                # Verificar si este chunk es de un art√≠culo ya incluido
                es_duplicado = False
                for num_art in articulos_ya_incluidos:
                    if f"Art√≠culo {num_art}" in texto or f"Art. {num_art}" in texto:
                        es_duplicado = True
                        break
                
                if not es_duplicado:
                    texto_corregido = corregir_encoding(texto)
                    contexto_parts.append(
                        f"[Fragmento del C√≥digo Penal - Relevancia: {score:.2f}]"
                        f"\n{texto_corregido}"
                    )
            
            contexto = "\n\n---\n\n".join(contexto_parts)
            num_matches = len(contexto_parts)
            articulos_completos = sum(1 for info in articulos_reconstruidos.values() if info['completo'])
            articulos_incompletos = len(articulos_reconstruidos) - articulos_completos
            
            print(f"üìã Contexto final: {num_matches} fragmentos")
            print(f"   - {articulos_completos} art√≠culos completos reconstruidos")
            print(f"   - {articulos_incompletos} art√≠culos parciales")
            print(f"   - Total: {len(contexto)} caracteres")
        
        else:
            # Sin reconstrucci√≥n - m√©todo original
            print(f"\nüìã Construcci√≥n de contexto sin reconstrucci√≥n...")
            contexto_parts = []
            for match in chunks_relevantes:
                text = match.get('metadata', {}).get('text', '')
                score = match.get('score', 0)
                if text:
                    texto_corregido = corregir_encoding(text)
                    contexto_parts.append(f"[Fragmento del C√≥digo Penal - Relevancia: {score:.2f}]\n{texto_corregido}")
            
            contexto = "\n\n---\n\n".join(contexto_parts)
            num_matches = len(contexto_parts)
            print(f"üìã Contexto construido: {num_matches} fragmentos ({len(contexto)} caracteres)")

        # --- PASO 9: GENERAR RESPUESTA CON GEMINI ---
        
        # Ajustar l√≠mites de concisi√≥n seg√∫n si es consulta de seguimiento
        es_seguimiento = query_enriquecida != query  # Si se enriqueci√≥, es seguimiento
        
        # Si hay nota de correcci√≥n, usarla (tiene prioridad sobre seguimiento)
        if nota_correccion:
            nota_contextual = nota_correccion
            # En correcciones, mantener l√≠mites normales (el usuario sabe qu√© quiere)
            limite_articulos = "1-3 art√≠culos"
            limite_max_articulos = "5 art√≠culos"
            limite_penas = "2-5 penas"
            limite_max_penas = "8 penas"
        elif es_seguimiento:
            limite_articulos = "4-8 art√≠culos"
            limite_max_articulos = "12 art√≠culos"
            limite_penas = "4-12 penas"
            limite_max_penas = "12 penas"
            
            # Extraer la √∫ltima consulta del usuario del historial
            ultima_consulta_usuario = ""
            for msg in reversed(historial):
                if msg.role == "user":
                    ultima_consulta_usuario = msg.content
                    break
            
            nota_seguimiento = f"""
**‚ö†Ô∏è CONTEXTO CONVERSACIONAL - CONSULTA DE SEGUIMIENTO:**
El usuario est√° continuando una conversaci√≥n previa. Esta consulta hace referencia a m√∫ltiples aspectos:

- **Consulta anterior:** "{ultima_consulta_usuario}"
- **Consulta actual:** "{query}"
- **CONSULTA COMPLETA INTERPRETADA:** "{query_enriquecida}"

**INSTRUCCI√ìN CR√çTICA:** 
Debes analizar y responder sobre TODOS los delitos/aspectos mencionados en la "CONSULTA COMPLETA INTERPRETADA" con IGUAL importancia y detalle. No priorices solo el √∫ltimo tema mencionado - dedica espacio y art√≠culos similares a CADA aspecto del caso.

Ejemplo: Si la consulta completa es "robo de coche y adem√°s atropello mortal", debes explicar AMBOS delitos (robo + atropello) con similar nivel de detalle, art√≠culos y penas.
"""
            nota_contextual = nota_seguimiento
        else:
            limite_articulos = "3-5 art√≠culos"
            limite_max_articulos = "6 art√≠culos"
            limite_penas = "3-6 penas"
            limite_max_penas = "6 penas"
            nota_contextual = ""
        
        prompt = f"""Act√∫a como un asistente jur√≠dico especializado en Derecho Penal espa√±ol. Tu conocimiento se basa exclusivamente en el texto oficial del C√≥digo Penal.

{nota_contextual}

CONSULTA DEL USUARIO:
{query_enriquecida}

CONTEXTO RECUPERADO ({num_matches} fragmentos del C√≥digo Penal):
{contexto}

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

PROTOCOLO DE RESPUESTA:

**1. Si el usuario pregunta por un art√≠culo espec√≠fico** (ej: "142", "art√≠culo 138"):
   - Muestra el texto COMPLETO y LITERAL del art√≠culo
   - Formato: **Art√≠culo [n√∫mero].** seguido del texto completo
   - NO resumas, cita el texto tal como aparece en el C√≥digo Penal
   - NO apliques el formato de ficha estructurada

**2. Si es una consulta conceptual sobre un delito o situaci√≥n** (ej: "violaci√≥n a menor", "robo de coche con accidente"):
   Genera una ficha legal completa, clara y visualmente ordenada con este formato:

---
## **[T√çTULO DEL DELITO]**

### **Art√≠culos relevantes:**
- **Art. [n√∫mero]** ‚Äì [nombre o resumen breve del tipo penal]
- **Art. [n√∫mero]** ‚Äì [nombre o resumen breve del tipo penal]

**L√çMITES DE CONCISI√ìN:**
- **Recomendado: {limite_articulos}** (los m√°s directamente relevantes)
- **M√°ximo: {limite_max_articulos}** (solo si el caso es muy complejo con m√∫ltiples delitos en concurso)
- Prioriza CALIDAD sobre CANTIDAD: mejor 3 art√≠culos bien explicados que 6 superficiales

### **Penas aplicables:**
- **Art. [n√∫mero]:** [pena concreta: prisi√≥n de X a Y a√±os, multa de X a Y meses, inhabilitaci√≥n, etc.]
- **Art. [n√∫mero]:** [pena concreta con todas las condiciones aplicables]
- **Agravantes/Atenuantes:** [factores que modifican la pena si aplican]

**L√çMITES DE CONCISI√ìN:**
- **Recomendado: {limite_penas}** (las principales para cada art√≠culo relevante)
- **M√°ximo: {limite_max_penas}** (si hay varios delitos acumulables o m√∫ltiples agravantes)
- Si hay muchos art√≠culos, agrupa las penas similares en lugar de listarlas todas

**IMPORTANTE:** Usa SIEMPRE n√∫meros para expresar las penas (ej: "de 1 a 6 meses", "de 2 a 5 a√±os"), NUNCA escribas los n√∫meros en letra (NO "de uno a seis meses").

### **Explicaci√≥n legal:**
Redacta un p√°rrafo claro y conciso explicando:
- C√≥mo encaja el delito en el C√≥digo Penal
- Cu√°ndo se aplicar√≠a cada art√≠culo seg√∫n el contexto (violencia, imprudencia, dolo, etc.)
- Qu√© factores agravan o aten√∫an la pena
- Si hay dolo (intenci√≥n) o imprudencia
- Si el delito no aparece directamente, qu√© art√≠culos lo cubren por analog√≠a

### **Resumen final:**
**‚Üí** [Resumen corto tipo f√≥rmula: delito + agravantes + art√≠culos principales]  
**‚Üí** [Rango de penas aproximado: prisi√≥n de X a Y a√±os + multa + inhabilitaci√≥n + otras consecuencias]

**IMPORTANTE:** En el resumen tambi√©n usa n√∫meros para las penas (ej: "de 2 a 5 a√±os"), no los escribas en letra.

---

**3. Reglas de estilo y contenido:**
   - Mant√©n un tono profesional, directo y visualmente limpio
   - Prioriza la claridad: cada punto debe poder leerse en 10-15 segundos
   - Usa terminolog√≠a legal precisa (NO uses "aproximadamente", "m√°s o menos")
   - Diferencia claramente entre dolo (intenci√≥n) e imprudencia
   - SIEMPRE menciona las penas exactas (prisi√≥n, multa, inhabilitaci√≥n)
   - Basa tu respuesta EXCLUSIVAMENTE en el contexto proporcionado
   - No incluyas notas doctrinales, jurisprudencia ni referencias externas
   - Si falta informaci√≥n clave, ind√≠calo claramente

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

EJEMPLO DE FICHA BIEN ESTRUCTURADA (respetando l√≠mites de concisi√≥n):

---
## **Agresi√≥n con cuchillo sin causar la muerte**

### **Art√≠culos relevantes:**
- **Art. 147** ‚Äì Lesiones dolosas con instrumento peligroso
- **Art. 148** ‚Äì Agravantes por uso de armas o medios peligrosos
- **Art. 20** ‚Äì Eximentes (leg√≠tima defensa, estado de necesidad)

(Nota: Solo 3 art√≠culos - los m√°s relevantes. NO agregues m√°s a menos que sea estrictamente necesario)

### **Penas aplicables:**
- **Art. 147.1:** Prisi√≥n de 3 a 6 meses o multa de 6 a 12 meses (lesiones que requieren tratamiento m√©dico)
- **Art. 148.1:** Prisi√≥n de 2 a 5 a√±os (si se usan armas, instrumentos peligrosos o hay ensa√±amiento)
- **Agravantes:** Si hay alevos√≠a, premeditaci√≥n o la v√≠ctima es vulnerable, la pena puede elevarse al tipo superior

(Nota: Solo 3 penas principales. Si hubiera m√°s art√≠culos, agr√∫palas en lugar de listar todas)

### **Explicaci√≥n legal:**
El uso de un cuchillo en una agresi√≥n se considera empleo de instrumento peligroso, lo que agrava autom√°ticamente las lesiones seg√∫n el Art. 148. Si las lesiones requieren tratamiento m√©dico o quir√∫rgico (m√°s all√° de primera asistencia), se aplica el Art. 147. La intenci√≥n dolosa es clave: si hubo premeditaci√≥n, la pena es m√°s severa. Si no se caus√≥ la muerte, no aplican los tipos de homicidio (Arts. 138-140), pero si hubo intenci√≥n de matar y esta no se consum√≥, podr√≠a configurarse tentativa de homicidio (Arts. 62 + 138).

### **Resumen final:**
**‚Üí** Agresi√≥n con cuchillo + lesiones = Arts. 147 + 148 = delito doloso contra la integridad f√≠sica  
**‚Üí** Penas: Prisi√≥n de 2 a 5 a√±os + posible indemnizaci√≥n a la v√≠ctima + antecedentes penales

(Nota: F√≠jate que las penas se escriben con N√öMEROS: "2 a 5 a√±os", no "dos a cinco a√±os")

---

RESPONDE AHORA:"""

        print("‚öñÔ∏è Generando respuesta con Gemini (Vertex AI)...")
        response = LLM_CLIENT.generate_content(prompt)
        
        print("‚úÖ Respuesta generada exitosamente")
        return {
            "respuesta": response.text,
            "metadata": {
                "num_fragmentos": num_matches,
                "tiene_contexto": True,
                "modelo": MODEL_NAME,
                "embedding_model": EMBEDDING_MODEL,
                "metodo": "rag_vector_search"
            }
        }

    except Exception as e:
        print(f"‚ùå Error en el proceso RAG: {e}")
        import traceback
        traceback.print_exc()
        return {
            "respuesta": f"Disculpa, ha ocurrido un error al consultar la base de datos de documentos: {str(e)}",
            "metadata": {
                "error": True,
                "mensaje_error": str(e),
                "num_fragmentos": 0,
                "tiene_contexto": False
            }
        }
# --- 5. ENDPOINT PRINCIPAL DE CHAT ---
@app.post("/chat", response_model=ChatResponse)
async def handle_chat_request(request: ChatRequest):
    """
    Endpoint principal que procesa la pregunta del usuario y devuelve una respuesta
    basada en el contexto del C√≥digo Penal usando Vertex AI.
    
    ‚ö° MEJORA #3: Soporte para historial conversacional
    """
    pregunta_usuario = request.pregunta
    historial = request.historial if hasattr(request, 'historial') else []
    
    print(f"\n{'='*60}")
    print(f"üì® Nueva petici√≥n recibida")
    if historial:
        print(f"üí¨ Con historial de {len(historial)} mensajes")
    print(f"{'='*60}")
    
    # Llamar a la funci√≥n RAG con Vertex AI, pasando el historial
    resultado = generate_rag_response(pregunta_usuario, historial)
    
    return ChatResponse(
        respuesta=resultado["respuesta"],
        metadata={
            "pregunta": pregunta_usuario,
            "tieneContexto": resultado["metadata"].get("tiene_contexto", False),
            "numeroResultados": resultado["metadata"].get("num_fragmentos", 0),
            "modelo": resultado["metadata"].get("modelo", MODEL_NAME),
            "dominio": "codigo-penal-espanol",
            "proveedor": "Vertex AI (Google Cloud)"
        }
    )


# --- 6. ENDPOINT DE SALUD ---
@app.get("/health")
async def health_check():
    """Endpoint para verificar que la API est√° funcionando"""
    return {
        "status": "healthy",
        "service": "RAG API - C√≥digo Penal (Vertex AI)",
        "version": "2.0.0",
        "provider": "Google Cloud Vertex AI",
        "models": {
            "llm": MODEL_NAME,
            "embeddings": EMBEDDING_MODEL
        }
    }


# --- 7. ENDPOINT DE INFORMACI√ìN ---
@app.get("/")
async def root():
    """Informaci√≥n b√°sica de la API"""
    return {
        "message": "API RAG - C√≥digo Penal Espa√±ol (Vertex AI)",
        "version": "2.0.0",
        "provider": "Google Cloud Platform",
        "endpoints": {
            "chat": "/chat (POST)",
            "health": "/health (GET)",
            "docs": "/docs (Documentaci√≥n interactiva)"
        },
        "models": {
            "generacion": MODEL_NAME,
            "embeddings": EMBEDDING_MODEL
        }
    }

