# main.py
# Backend API para el sistema RAG de consultas legales
# VersiÃ³n con Vertex AI (Google Cloud)

import os
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from dotenv import load_dotenv

# --- IMPORTS ADICIONALES PARA RAG CON VERTEX AI ---
from google.cloud import aiplatform
from vertexai.language_models import TextEmbeddingModel
from vertexai.generative_models import GenerativeModel
from pinecone import Pinecone
import vertexai

# Cargar las variables de entorno desde .env
load_dotenv()

# --- 1. CONFIGURACIÃ“N DE VERTEX AI Y PINECONE ---
PROJECT_ID = os.getenv("GCP_PROJECT_ID", "resolute-return-476416-g5")
REGION = os.getenv("GCP_REGION", "us-central1")
MODEL_NAME = "gemini-2.0-flash-001"  # Modelo de generaciÃ³n
EMBEDDING_MODEL = "text-embedding-004"  # Modelo de embeddings de Google

# ConfiguraciÃ³n de Pinecone
PINECONE_API_KEY = os.getenv("PINECONE_API_KEY")
PINECONE_INDEX_NAME = os.getenv("PINECONE_INDEX_NAME", "codigo-penal-vertex-ai")
TOP_K_RESULTS = 10  # Aumentado para capturar mÃ¡s contexto y encontrar artÃ­culos especÃ­ficos

# --- INICIALIZACIÃ“N DE SERVICIOS ---
print("ğŸ”§ Inicializando Vertex AI y Pinecone...")

# Variable global para texto completo del PDF (para bÃºsqueda exacta)
TEXTO_COMPLETO_PDF = None

try:
    # A. Inicializar Vertex AI
    vertexai.init(project=PROJECT_ID, location=REGION)
    print(f"âœ… Vertex AI inicializado - Proyecto: {PROJECT_ID}, RegiÃ³n: {REGION}")
    
    # B. Inicializar Pinecone
    pc = Pinecone(api_key=PINECONE_API_KEY)
    PINECONE_INDEX = pc.Index(PINECONE_INDEX_NAME)
    print(f"âœ… Pinecone conectado - Ãndice: {PINECONE_INDEX_NAME}")

    # C. Cargar Modelos de Vertex AI
    EMBEDDING_CLIENT = TextEmbeddingModel.from_pretrained(EMBEDDING_MODEL)
    LLM_CLIENT = GenerativeModel(MODEL_NAME)
    print(f"âœ… Modelos cargados - Embeddings: {EMBEDDING_MODEL}, LLM: {MODEL_NAME}")
    
    # D. Cargar texto completo del PDF para bÃºsqueda exacta
    try:
        import PyPDF2
        pdf_path = "../documentos/codigo_penal.pdf"
        with open(pdf_path, 'rb') as file:
            pdf_reader = PyPDF2.PdfReader(file)
            texto_paginas = []
            for page in pdf_reader.pages:
                texto_paginas.append(page.extract_text())
            TEXTO_COMPLETO_PDF = "\n".join(texto_paginas)
            print(f"âœ… PDF cargado para bÃºsqueda exacta ({len(TEXTO_COMPLETO_PDF)} caracteres)")
    except Exception as e:
        print(f"âš ï¸ No se pudo cargar PDF completo: {e} (bÃºsqueda exacta deshabilitada)")
    
    print("âœ… Â¡InicializaciÃ³n completada con Ã©xito!")

except Exception as e:
    print(f"âŒ ERROR DE INICIALIZACIÃ“N: {e}")
    raise


# --- 2. MODELOS DE DATOS ---
class ChatRequest(BaseModel):
    pregunta: str


class ChatResponse(BaseModel):
    respuesta: str
    metadata: dict = None


# --- 3. INICIALIZAR LA APLICACIÃ“N ---
app = FastAPI(
    title="API RAG - CÃ³digo Penal EspaÃ±ol",
    description="API para consultas sobre el CÃ³digo Penal usando RAG",
    version="1.0.0"
)

# Configurar CORS para permitir peticiones desde el frontend
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # En producciÃ³n, especifica tu dominio exacto
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


# --- 4. FUNCIÃ“N CENTRAL DE RAG CON VERTEX AI ---

def buscar_articulo_exacto(texto_completo: str, numero_articulo: str) -> str:
    """
    Busca un artÃ­culo especÃ­fico en el texto completo del PDF usando regex.
    Soporta artÃ­culos simples (142) y con sufijos (142 bis, 127 ter, etc.)
    """
    import re
    
    # Normalizar el nÃºmero de artÃ­culo (puede venir como "127 bis" o "127")
    numero_articulo = numero_articulo.strip()
    
    # Si tiene bis/ter/quater, buscar exactamente ese artÃ­culo
    if re.search(r'\b(bis|ter|quater)\b', numero_articulo, re.IGNORECASE):
        # Buscar "ArtÃ­culo 127 bis" especÃ­ficamente
        pattern = rf"(?i)(art[Ã­i]culo\s+{re.escape(numero_articulo)})[\.\s]+(.+?)(?=\n\s*Art[Ã­i]culo\s+\d+|\Z)"
    else:
        # Buscar "ArtÃ­culo N" pero NO "ArtÃ­culo N bis/ter/quater"
        pattern = rf"(?i)(art[Ã­i]culo\s+{numero_articulo})\s+(?!bis|ter|quater)(.+?)(?=\n\s*Art[Ã­i]culo\s+\d+\s|\Z)"
    
    match = re.search(pattern, texto_completo, re.DOTALL | re.IGNORECASE)
    
    if match:
        # Incluir el encabezado completo "ArtÃ­culo N"
        texto_articulo = match.group(0).strip()
        
        # NO truncar - devolver el artÃ­culo completo
        # Si es muy largo, el flujo principal decidirÃ¡ si pasarlo por Gemini
        return texto_articulo
    
    return None


def corregir_encoding(texto: str) -> str:
    """
    Corrige problemas de encoding comunes en el PDF del CÃ³digo Penal
    """
    # Reemplazos bÃ¡sicos de caracteres corruptos
    texto = texto.replace('ÃƒÂ­', 'Ã­')
    texto = texto.replace('ÃƒÂ³', 'Ã³')
    texto = texto.replace('ÃƒÂ±', 'Ã±')
    texto = texto.replace('ÃƒÂ¡', 'Ã¡')
    texto = texto.replace('ÃƒÂ©', 'Ã©')
    texto = texto.replace('ÃƒÂº', 'Ãº')
    texto = texto.replace('ÃƒÂ¼', 'Ã¼')
    texto = texto.replace('ÃƒÂ¶', 'Ã¶')
    
    # MayÃºsculas
    texto = texto.replace('Ãƒ', 'Ã')
    texto = texto.replace('Ãƒâ€°', 'Ã‰')
    texto = texto.replace('Ãƒ"', 'Ã“')
    texto = texto.replace('ÃƒÅ¡', 'Ãš')
    
    # Eliminar caracteres basura
    texto = texto.replace('Ã‚', '')
    
    return texto


def generate_rag_response(query: str):
    """
    Sistema RAG hÃ­brido con bÃºsqueda exacta + vector search.
    
    1. Detecta si es consulta de artÃ­culo especÃ­fico
    2. Intenta bÃºsqueda exacta con regex primero
    3. Si no encuentra, usa RAG con embeddings
    4. Corrige encoding en todos los resultados
    """
    try:
        print(f"\n{'='*80}")
        print(f"ğŸ“¨ CONSULTA: {query}")
        print(f"{'='*80}")

        # --- PASO 1: DETECTAR NÃšMERO DE ARTÃCULO ---
        import re
        articulo_pattern = r'\b(?:art[Ã­i]culo|art\.?)\s*(\d+(?:\s+bis|\s+ter|\s+quater)?)\b'
        solo_numero_pattern = r'^\s*(\d+(?:\s+bis|\s+ter|\s+quater)?)\s*$'
        
        numero_articulo = None
        match_articulo = re.search(articulo_pattern, query, re.IGNORECASE)
        match_numero = re.match(solo_numero_pattern, query)
        
        if match_articulo:
            numero_articulo = match_articulo.group(1)
            print(f"ğŸ¯ ArtÃ­culo detectado (patrÃ³n completo): {numero_articulo}")
        elif match_numero:
            numero_articulo = match_numero.group(1)
            print(f"ğŸ¯ ArtÃ­culo detectado (solo nÃºmero): {numero_articulo}")
        
        # DEBUG: Verificar estado del PDF
        if numero_articulo:
            print(f"ğŸ“„ TEXTO_COMPLETO_PDF disponible: {TEXTO_COMPLETO_PDF is not None}")
            if TEXTO_COMPLETO_PDF:
                print(f"ğŸ“„ TamaÃ±o del PDF: {len(TEXTO_COMPLETO_PDF)} caracteres")
        
        # --- PASO 2: BÃšSQUEDA EXACTA (si hay nÃºmero de artÃ­culo y PDF cargado) ---
        if numero_articulo and TEXTO_COMPLETO_PDF:
            print(f"ğŸ” Intentando bÃºsqueda exacta para artÃ­culo {numero_articulo}...")
            texto_exacto = buscar_articulo_exacto(TEXTO_COMPLETO_PDF, numero_articulo)
            
            if texto_exacto:
                print(f"âœ… Â¡ArtÃ­culo {numero_articulo} encontrado con bÃºsqueda exacta!")
                texto_corregido = corregir_encoding(texto_exacto)
                
                # Responder directamente sin pasar por Gemini si es texto razonable
                # Aumentado a 4000 caracteres (la mayorÃ­a de artÃ­culos caben)
                if len(texto_corregido) < 4000:
                    respuesta_final = f"**ArtÃ­culo {numero_articulo}**\n\n{texto_corregido}"
                    return {
                        "respuesta": respuesta_final,
                        "metadata": {
                            "num_fragmentos": 1,
                            "tiene_contexto": True,
                            "modelo": "BÃºsqueda exacta (sin LLM)",
                            "embedding_model": "N/A",
                            "metodo": "exact_match"
                        }
                    }
                else:
                    # Si es muy largo (>4000 chars), pasar por Gemini para formatear mejor
                    prompt = f"""Eres un asistente legal especializado en el CÃ³digo Penal espaÃ±ol.

El usuario preguntÃ³: "{query}"

AquÃ­ estÃ¡ el texto LITERAL y COMPLETO del artÃ­culo encontrado:

{texto_corregido}

INSTRUCCIONES:
1. Responde con el texto COMPLETO del artÃ­culo tal como aparece
2. NO resumas ni parafrasees - cita el texto literal
3. Organiza el contenido de forma clara usando formato Markdown
4. MantÃ©n TODOS los apartados, nÃºmeros y subapartados
5. Usa el formato: **ArtÃ­culo [nÃºmero].** seguido del texto completo

Responde ahora:"""

                    response = LLM_CLIENT.generate_content(prompt)
                    return {
                        "respuesta": response.text,
                        "metadata": {
                            "num_fragmentos": 1,
                            "tiene_contexto": True,
                            "modelo": MODEL_NAME,
                            "embedding_model": "N/A",
                            "metodo": "exact_match_formatted"
                        }
                    }

        # --- PASO 3: ENRIQUECER QUERY (si no hubo match exacto) ---
        if numero_articulo:
            query_enriquecida = (
                f"Contenido literal del CÃ³digo Penal espaÃ±ol "
                f"ArtÃ­culo {numero_articulo} delito pena castigo texto completo"
            )
            print(f"ğŸ”„ Query enriquecida: {query_enriquecida}")
        else:
            query_enriquecida = query

        # --- PASO 4: GENERAR EMBEDDING ---
        print("ğŸ”¢ Generando embedding con Vertex AI...")
        embeddings = EMBEDDING_CLIENT.get_embeddings([query_enriquecida])
        query_vector = embeddings[0].values
        print(f"âœ… Embedding generado: {len(query_vector)} dimensiones")

        # --- PASO 5: BÃšSQUEDA VECTORIAL EN PINECONE ---
        print(f"ğŸ” Buscando en Pinecone (TOP_K={TOP_K_RESULTS})...")
        results = PINECONE_INDEX.query(
            vector=query_vector,
            top_k=TOP_K_RESULTS,
            include_metadata=True
        )

        # --- PASO 6: FILTRADO ADAPTATIVO ---
        umbral = 0.35 if numero_articulo else 0.45
        print(f"ğŸ“Š Aplicando umbral adaptativo: {umbral}")
        
        contexto_parts = []
        for match in results['matches']:
            score = match.get('score', 0)
            print(f"  ğŸ“Š Match con score: {score:.3f}")
            
            if score > umbral:
                text = match.get('metadata', {}).get('text', '')
                if text:
                    # Corregir encoding del texto recuperado
                    texto_corregido = corregir_encoding(text)
                    contexto_parts.append(f"[Fragmento del CÃ³digo Penal - Relevancia: {score:.2f}]\n{texto_corregido}")
                    print(f"  âœ“ Fragmento aceptado (score: {score:.3f})")

        if not contexto_parts:
            print("âš ï¸ No hay resultados relevantes despuÃ©s del filtrado")
            return {
                "respuesta": "Lo siento, no encontrÃ© informaciÃ³n relevante en el CÃ³digo Penal sobre tu consulta. Â¿PodrÃ­as reformularla o ser mÃ¡s especÃ­fico?",
                "metadata": {
                    "num_fragmentos": 0,
                    "tiene_contexto": False,
                    "modelo": MODEL_NAME,
                    "embedding_model": EMBEDDING_MODEL,
                    "metodo": "rag_vector_search"
                }
            }

        contexto = "\n\n---\n\n".join(contexto_parts)
        num_matches = len(contexto_parts)
        print(f"ğŸ“‹ Contexto construido: {num_matches} fragmentos ({len(contexto)} caracteres)")

        # --- PASO 7: GENERAR RESPUESTA CON GEMINI ---
        prompt = f"""ActÃºa como un asistente jurÃ­dico especializado en Derecho Penal espaÃ±ol. Tu conocimiento se basa exclusivamente en el texto oficial del CÃ³digo Penal.

CONSULTA DEL USUARIO:
{query}

CONTEXTO RECUPERADO ({num_matches} fragmentos del CÃ³digo Penal):
{contexto}

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

PROTOCOLO DE RESPUESTA:

**1. Si el usuario pregunta por un artÃ­culo especÃ­fico** (ej: "142", "artÃ­culo 138"):
   - Muestra el texto COMPLETO y LITERAL del artÃ­culo
   - Formato: **ArtÃ­culo [nÃºmero].** seguido del texto completo
   - NO resumas, cita el texto tal como aparece en el CÃ³digo Penal
   - NO apliques el formato de ficha estructurada

**2. Si es una consulta conceptual sobre un delito o situaciÃ³n** (ej: "violaciÃ³n a menor", "robo de coche con accidente"):
   Genera una ficha legal completa, clara y visualmente ordenada con este formato:

---
## **[TÃTULO DEL DELITO]**

### **ArtÃ­culos relevantes:**
- **Art. [nÃºmero]** â€“ [nombre o resumen breve del tipo penal]
- **Art. [nÃºmero]** â€“ [nombre o resumen breve del tipo penal]
(mÃ¡ximo 5 artÃ­culos, los mÃ¡s relacionados con la consulta)

### **Penas aplicables:**
- **Art. [nÃºmero]:** [pena concreta: prisiÃ³n de X a Y aÃ±os, multa de X a Y meses, inhabilitaciÃ³n, etc.]
- **Art. [nÃºmero]:** [pena concreta con todas las condiciones aplicables]
- **Agravantes/Atenuantes:** [factores que modifican la pena si aplican]

**IMPORTANTE:** Usa SIEMPRE nÃºmeros para expresar las penas (ej: "de 1 a 6 meses", "de 2 a 5 aÃ±os"), NUNCA escribas los nÃºmeros en letra (NO "de uno a seis meses").

### **ExplicaciÃ³n legal:**
Redacta un pÃ¡rrafo claro y conciso explicando:
- CÃ³mo encaja el delito en el CÃ³digo Penal
- CuÃ¡ndo se aplicarÃ­a cada artÃ­culo segÃºn el contexto (violencia, imprudencia, dolo, etc.)
- QuÃ© factores agravan o atenÃºan la pena
- Si hay dolo (intenciÃ³n) o imprudencia
- Si el delito no aparece directamente, quÃ© artÃ­culos lo cubren por analogÃ­a

### **Resumen final:**
**â†’** [Resumen corto tipo fÃ³rmula: delito + agravantes + artÃ­culos principales]  
**â†’** [Rango de penas aproximado: prisiÃ³n de X a Y aÃ±os + multa + inhabilitaciÃ³n + otras consecuencias]

**IMPORTANTE:** En el resumen tambiÃ©n usa nÃºmeros para las penas (ej: "de 2 a 5 aÃ±os"), no los escribas en letra.

---

**3. Reglas de estilo y contenido:**
   - MantÃ©n un tono profesional, directo y visualmente limpio
   - Prioriza la claridad: cada punto debe poder leerse en 10-15 segundos
   - Usa terminologÃ­a legal precisa (NO uses "aproximadamente", "mÃ¡s o menos")
   - Diferencia claramente entre dolo (intenciÃ³n) e imprudencia
   - SIEMPRE menciona las penas exactas (prisiÃ³n, multa, inhabilitaciÃ³n)
   - Basa tu respuesta EXCLUSIVAMENTE en el contexto proporcionado
   - No incluyas notas doctrinales, jurisprudencia ni referencias externas
   - Si falta informaciÃ³n clave, indÃ­calo claramente

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

EJEMPLO DE FICHA BIEN ESTRUCTURADA:

---
## **AgresiÃ³n con cuchillo sin causar la muerte**

### **ArtÃ­culos relevantes:**
- **Art. 147** â€“ Lesiones dolosas con instrumento peligroso
- **Art. 148** â€“ Agravantes por uso de armas o medios peligrosos
- **Art. 20** â€“ Eximentes (legÃ­tima defensa, estado de necesidad)

### **Penas aplicables:**
- **Art. 147.1:** PrisiÃ³n de 3 a 6 meses o multa de 6 a 12 meses (lesiones que requieren tratamiento mÃ©dico)
- **Art. 148.1:** PrisiÃ³n de 2 a 5 aÃ±os (si se usan armas, instrumentos peligrosos o hay ensaÃ±amiento)
- **Agravantes:** Si hay alevosÃ­a, premeditaciÃ³n o la vÃ­ctima es vulnerable, la pena puede elevarse al tipo superior

### **ExplicaciÃ³n legal:**
El uso de un cuchillo en una agresiÃ³n se considera empleo de instrumento peligroso, lo que agrava automÃ¡ticamente las lesiones segÃºn el Art. 148. Si las lesiones requieren tratamiento mÃ©dico o quirÃºrgico (mÃ¡s allÃ¡ de primera asistencia), se aplica el Art. 147. La intenciÃ³n dolosa es clave: si hubo premeditaciÃ³n, la pena es mÃ¡s severa. Si no se causÃ³ la muerte, no aplican los tipos de homicidio (Arts. 138-140), pero si hubo intenciÃ³n de matar y esta no se consumÃ³, podrÃ­a configurarse tentativa de homicidio (Arts. 62 + 138).

### **Resumen final:**
**â†’** AgresiÃ³n con cuchillo + lesiones = Arts. 147 + 148 = delito doloso contra la integridad fÃ­sica  
**â†’** Penas: PrisiÃ³n de 2 a 5 aÃ±os + posible indemnizaciÃ³n a la vÃ­ctima + antecedentes penales

(Nota: FÃ­jate que las penas se escriben con NÃšMEROS: "2 a 5 aÃ±os", no "dos a cinco aÃ±os")

---

RESPONDE AHORA:"""

        print("âš–ï¸ Generando respuesta con Gemini (Vertex AI)...")
        response = LLM_CLIENT.generate_content(prompt)
        
        print("âœ… Respuesta generada exitosamente")
        return {
            "respuesta": response.text,
            "metadata": {
                "num_fragmentos": num_matches,
                "tiene_contexto": True,
                "modelo": MODEL_NAME,
                "embedding_model": EMBEDDING_MODEL,
                "metodo": "rag_vector_search"
            }
        }

    except Exception as e:
        print(f"âŒ Error en el proceso RAG: {e}")
        import traceback
        traceback.print_exc()
        return {
            "respuesta": f"Disculpa, ha ocurrido un error al consultar la base de datos de documentos: {str(e)}",
            "metadata": {
                "error": True,
                "mensaje_error": str(e),
                "num_fragmentos": 0,
                "tiene_contexto": False
            }
        }
# --- 5. ENDPOINT PRINCIPAL DE CHAT ---
@app.post("/chat", response_model=ChatResponse)
async def handle_chat_request(request: ChatRequest):
    """
    Endpoint principal que procesa la pregunta del usuario y devuelve una respuesta
    basada en el contexto del CÃ³digo Penal usando Vertex AI.
    """
    pregunta_usuario = request.pregunta
    print(f"\n{'='*60}")
    print(f"ï¿½ Nueva peticiÃ³n recibida")
    print(f"{'='*60}")
    
    # Llamar a la funciÃ³n RAG con Vertex AI
    resultado = generate_rag_response(pregunta_usuario)
    
    return ChatResponse(
        respuesta=resultado["respuesta"],
        metadata={
            "pregunta": pregunta_usuario,
            "tieneContexto": resultado["metadata"].get("tiene_contexto", False),
            "numeroResultados": resultado["metadata"].get("num_fragmentos", 0),
            "modelo": resultado["metadata"].get("modelo", MODEL_NAME),
            "dominio": "codigo-penal-espanol",
            "proveedor": "Vertex AI (Google Cloud)"
        }
    )


# --- 6. ENDPOINT DE SALUD ---
@app.get("/health")
async def health_check():
    """Endpoint para verificar que la API estÃ¡ funcionando"""
    return {
        "status": "healthy",
        "service": "RAG API - CÃ³digo Penal (Vertex AI)",
        "version": "2.0.0",
        "provider": "Google Cloud Vertex AI",
        "models": {
            "llm": MODEL_NAME,
            "embeddings": EMBEDDING_MODEL
        }
    }


# --- 7. ENDPOINT DE INFORMACIÃ“N ---
@app.get("/")
async def root():
    """InformaciÃ³n bÃ¡sica de la API"""
    return {
        "message": "API RAG - CÃ³digo Penal EspaÃ±ol (Vertex AI)",
        "version": "2.0.0",
        "provider": "Google Cloud Platform",
        "endpoints": {
            "chat": "/chat (POST)",
            "health": "/health (GET)",
            "docs": "/docs (DocumentaciÃ³n interactiva)"
        },
        "models": {
            "generacion": MODEL_NAME,
            "embeddings": EMBEDDING_MODEL
        }
    }

