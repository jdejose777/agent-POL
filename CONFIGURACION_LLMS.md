# ğŸ¤– ConfiguraciÃ³n de LLMs de CÃ³digo Abierto para n8n

## ğŸ¯ Resumen de Cambios

He reemplazado el nodo de Google Gemini con un **nodo HTTP Request flexible** que te permite usar cualquier API de LLM de cÃ³digo abierto. Esto te da mÃ¡s opciones, mejor costo-beneficio y mayor control.

## ğŸ”§ ConfiguraciÃ³n del Nodo HTTP Request

### ParÃ¡metros Configurados:
- **Method**: `POST`
- **URL**: `URL_DE_LA_API_AQUI` (reemplazar segÃºn el proveedor)
- **Authentication**: `Header Auth`
- **Header Name**: `Authorization` 
- **Header Value**: `Bearer {{ $credentials.miApiKeySecreta }}`
- **Body Content Type**: `JSON`
- **Temperature**: `0.3` (respuestas objetivas)

## ğŸŒŸ Opciones de APIs Compatibles

### 1. ğŸš€ Groq (Recomendado - MÃ¡s RÃ¡pido)

**URL a usar:**
```
https://api.groq.com/openai/v1/chat/completions
```

**Modelos disponibles:**
- `llama3-8b-8192` (configurado por defecto)
- `llama3-70b-8192` 
- `mixtral-8x7b-32768`
- `gemma-7b-it`

**CÃ³mo obtener API Key:**
1. Ve a [console.groq.com](https://console.groq.com/)
2. Crea cuenta gratuita
3. Ve a API Keys
4. Crea nueva API key
5. Ãšsala en las credenciales de n8n

**Ventajas:**
- âœ… Muy rÃ¡pido (inferencia optimizada)
- âœ… Generoso plan gratuito
- âœ… Compatible con formato OpenAI
- âœ… Excelente para respuestas jurÃ­dicas

### 2. ğŸ¤— Hugging Face Inference API

**URL a usar:**
```
https://api-inference.huggingface.co/models/microsoft/DialoGPT-large
```

**Otros modelos compatibles:**
- `microsoft/DialoGPT-large`
- `facebook/blenderbot-400M-distill`
- `microsoft/DialoGPT-medium`

**CÃ³mo obtener API Key:**
1. Ve a [huggingface.co](https://huggingface.co/)
2. Crea cuenta â†’ Settings â†’ Access Tokens
3. Crea token con permisos de lectura
4. Ãšsala en las credenciales de n8n

**Ventajas:**
- âœ… Muchos modelos disponibles
- âœ… Plan gratuito
- âœ… Especializado en ML/NLP

### 3. ğŸ¦™ Ollama (Local)

**URL a usar:**
```
http://localhost:11434/api/generate
```

**Modelos recomendados:**
- `llama3:8b`
- `mistral:7b`
- `codellama:7b`

**ConfiguraciÃ³n:**
1. Instala Ollama en tu servidor
2. Descarga modelo: `ollama pull llama3:8b`
3. No necesitas API key (es local)
4. Cambia Authentication a "None"

**Ventajas:**
- âœ… 100% local y privado
- âœ… Sin costos de API
- âœ… Control total del modelo

## ğŸ” ConfiguraciÃ³n de Credenciales en n8n

### Paso 1: Crear Credencial
1. En n8n, ve a **Settings** â†’ **Credentials**
2. Clic en **Create new credential**
3. Busca **"API Key Auth"** o **"Generic Credential"**
4. Ponle nombre: `miApiKeySecreta`

### Paso 2: Configurar Credencial
```
Name: miApiKeySecreta
API Key: tu_api_key_aqui_sin_bearer
```

**Importante:** Solo pon la API key, **NO** incluyas "Bearer " porque ya estÃ¡ en el nodo.

## ğŸ›ï¸ PersonalizaciÃ³n del Prompt

El prompt estÃ¡ optimizado para respuestas jurÃ­dicas:

```javascript
"Eres un asistente jurÃ­dico especializado en el CÃ³digo Penal espaÃ±ol. 
Responde basÃ¡ndote Ãºnicamente en el contexto proporcionado del CÃ³digo Penal.

{{ $json.tieneContexto ? 'CONTEXTO DEL CÃ“DIGO PENAL:\n' + $json.contexto + '\n\n' : 'No se encontrÃ³ informaciÃ³n especÃ­fica en el CÃ³digo Penal para esta consulta.\n\n' }}

PREGUNTA:
{{ $json.pregunta }}

INSTRUCCIONES:
- Responde basÃ¡ndote Ãºnicamente en el contexto del CÃ³digo Penal proporcionado
- Si la informaciÃ³n no estÃ¡ en el contexto, indÃ­calo claramente
- Cita los artÃ­culos especÃ­ficos cuando sea posible
- Usa un lenguaje claro y profesional
- Si es relevante, menciona las penas asociadas

RESPUESTA:"
```

## ğŸ”„ Cambios en el Workflow

### Nuevos Nodos:
1. **ğŸ¤– LLM Open Source** - HTTP Request a tu API elegida
2. **ğŸ”§ Procesar Respuesta LLM** - Extrae la respuesta del formato de cada API

### Flujo Actualizado:
```
Webhook â†’ Embedding Python â†’ BÃºsqueda Pinecone â†’ LLM Open Source â†’ Procesar Respuesta â†’ Frontend
```

## ğŸ§ª Pruebas Recomendadas

### 1. Probar con Groq (Recomendado)
```bash
# ConfiguraciÃ³n rÃ¡pida:
URL: https://api.groq.com/openai/v1/chat/completions
Modelo: llama3-8b-8192
API Key: tu_groq_api_key
```

### 2. Fallback con Hugging Face
```bash
# Si Groq no funciona:
URL: https://api-inference.huggingface.co/models/microsoft/DialoGPT-large
API Key: tu_hf_token
```

## ğŸ’¡ Recomendaciones

### Para ProducciÃ³n:
- **Groq**: Mejor rendimiento y respuestas
- **Modelo**: `llama3-8b-8192` o `llama3-70b-8192`
- **Backup**: Configura Hugging Face como respaldo

### Para Desarrollo:
- **Ollama**: Desarrollo local sin costos
- **Modelo**: `llama3:8b` funciona bien
- **Sin API keys**: Perfecto para pruebas

## ğŸ†˜ Troubleshooting

### Error: "API Key invÃ¡lida"
- Verifica que la credencial `miApiKeySecreta` existe
- AsegÃºrate de no incluir "Bearer " en la API key
- Prueba la API key con curl directamente

### Error: "Modelo no encontrado"
- Cambia el modelo en el parÃ¡metro `model`
- Verifica que el modelo existe en tu proveedor elegido

### Error: "Respuesta vacÃ­a"
- El nodo "ğŸ”§ Procesar Respuesta LLM" maneja diferentes formatos
- Revisa los logs para ver quÃ© formato estÃ¡ llegando

Â¡El sistema ahora es mÃ¡s flexible y potente! ğŸš€