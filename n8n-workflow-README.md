# ü§ñ N8N Workflow - Agent POL RAG Chat

Este archivo contiene el workflow completo de n8n para el sistema de chat RAG. 

## üìã Descripci√≥n del Workflow

El workflow implementa un agente de chat inteligente que puede responder preguntas sobre documentos PDF procesados usando la siguiente arquitectura:

```
üéØ Webhook ‚Üí üß† Embedding ‚Üí üîç Pinecone ‚Üí ü§ñ GPT ‚Üí üì§ Respuesta
```

## üîß Nodos del Workflow

### 1. üéØ Webhook - Entrada del Chat
- **Tipo**: `n8n-nodes-base.webhook`
- **Funci√≥n**: Recibe las preguntas del frontend
- **Entrada esperada**: 
  ```json
  {
    "pregunta": "¬øQu√© dice el documento sobre...?"
  }
  ```
- **Path**: `rag-chat-agent`

### 2. üß† Generar Embedding
- **Tipo**: `n8n-nodes-base.code`
- **Funci√≥n**: Convierte la pregunta en embedding usando OpenAI
- **API utilizada**: OpenAI Embeddings API
- **Modelo**: `text-embedding-3-small`
- **Variables requeridas**: `OPENAI_API_KEY`

### 3. üîç B√∫squeda en Pinecone
- **Tipo**: `n8n-nodes-base.code`
- **Funci√≥n**: Busca contexto relevante en la base de datos vectorial
- **API utilizada**: Pinecone Query API
- **Par√°metros**: topK=5, score m√≠nimo=0.7
- **Variables requeridas**: 
  - `PINECONE_API_KEY`
  - `PINECONE_ENVIRONMENT`
  - `PINECONE_INDEX_NAME`

### 4. ü§ñ Generar Respuesta GPT
- **Tipo**: `n8n-nodes-base.code`
- **Funci√≥n**: Genera respuesta contextual usando GPT
- **API utilizada**: OpenAI Chat Completions API
- **Modelo**: `gpt-4o-mini`
- **Par√°metros**: max_tokens=500, temperature=0.7

### 5. üì§ Responder al Chat
- **Tipo**: `n8n-nodes-base.respondToWebhook`
- **Funci√≥n**: Devuelve la respuesta al frontend
- **Formato**: JSON con headers CORS
- **Respuesta**: 
  ```json
  {
    "respuesta": "Respuesta generada...",
    "metadata": {
      "pregunta": "Pregunta original",
      "tieneContexto": true,
      "numeroResultados": 3,
      "timestamp": "2025-10-07T10:30:00.000Z",
      "modelo": "gpt-4o-mini"
    }
  }
  ```

## ‚öôÔ∏è Variables de Entorno Requeridas

Configura estas variables en tu instancia de n8n:

```env
# OpenAI API
OPENAI_API_KEY=sk-...

# Pinecone Configuration
PINECONE_API_KEY=...
PINECONE_ENVIRONMENT=us-east-1
PINECONE_INDEX_NAME=nombre-de-tu-indice
```

## üöÄ C√≥mo Importar el Workflow

1. **Copia el contenido** de `plantilla_n8n.json`
2. **Abre n8n** en tu navegador
3. **Crea un nuevo workflow**
4. **Haz clic en el men√∫** (3 puntos) ‚Üí **Import from JSON**
5. **Pega el JSON** y confirma la importaci√≥n
6. **Configura las variables de entorno** en Settings ‚Üí Environment variables
7. **Activa el workflow**

## üîó URL del Webhook

Una vez importado y activado, tu webhook est√° configurado en:

```
https://jdejose.app.n8n.cloud/webhook/rag-chat-agent
```

Esta URL ya est√° configurada en el frontend (`app.js`):

```javascript
const WEBHOOK_URL = 'https://jdejose.app.n8n.cloud/webhook/rag-chat-agent';
```

## üß™ Pruebas del Workflow

### Prueba Manual en n8n
1. **Activa el workflow**
2. **Ve al nodo Webhook** y haz clic en "Listen for calls"
3. **Usa Postman o curl** para enviar una petici√≥n POST:

```bash
curl -X POST https://jdejose.app.n8n.cloud/webhook/rag-chat-agent \
  -H "Content-Type: application/json" \
  -d '{"pregunta": "¬øQu√© dice el documento sobre inteligencia artificial?"}'
```

### Respuesta Esperada
```json
{
  "respuesta": "Seg√∫n el documento procesado, la inteligencia artificial...",
  "metadata": {
    "pregunta": "¬øQu√© dice el documento sobre inteligencia artificial?",
    "tieneContexto": true,
    "numeroResultados": 3,
    "timestamp": "2025-10-07T10:30:00.000Z",
    "modelo": "gpt-4o-mini"
  }
}
```

## üõ†Ô∏è Personalizaci√≥n

### Ajustar Sensibilidad de B√∫squeda
En el nodo "üîç B√∫squeda en Pinecone", modifica:
```javascript
.filter(match => match.score > 0.7) // Cambiar 0.7 por el umbral deseado
```

### Cambiar Modelo de GPT
En el nodo "ü§ñ Generar Respuesta GPT", modifica:
```javascript
model: 'gpt-4o-mini', // Cambiar por 'gpt-4', 'gpt-3.5-turbo', etc.
```

### Ajustar Longitud de Respuesta
```javascript
max_tokens: 500, // Aumentar para respuestas m√°s largas
```

## üö® Soluci√≥n de Problemas

### Error: Variables de entorno no configuradas
- Verifica que todas las variables est√©n configuradas en n8n
- Reinicia el workflow despu√©s de configurar las variables

### Error: Pinecone API
- Verifica que el √≠ndice existe en Pinecone
- Confirma que el environment es correcto (us-east-1, etc.)

### Error: OpenAI API
- Verifica que tienes cr√©ditos en tu cuenta de OpenAI
- Confirma que la API key es v√°lida

### Sin contexto relevante
- Verifica que los PDFs fueron procesados correctamente
- Ajusta el umbral de similitud (score > 0.7)
- Revisa que el √≠ndice de Pinecone tiene datos

## üìä Monitoreo y Logs

El workflow incluye logging detallado en la consola de n8n:

- ‚úÖ Confirmaciones de √©xito
- ‚ö†Ô∏è Advertencias sobre contexto
- ‚ùå Errores con detalles espec√≠ficos
- üìä Estad√≠sticas de b√∫squeda y respuesta

## üîÑ Flujo de Datos

```mermaid
graph LR
    A[Frontend] -->|POST /webhook| B[Webhook]
    B --> C[Generar Embedding]
    C --> D[Buscar en Pinecone]
    D --> E[Generar Respuesta]
    E --> F[Responder]
    F -->|JSON Response| A
```

---

**Nota**: Este workflow est√° optimizado para ser eficiente y econ√≥mico, usando `gpt-4o-mini` y `text-embedding-3-small` que son los modelos m√°s cost-effective de OpenAI.