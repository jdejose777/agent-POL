"""
Script para procesar archivos PDF y cargarlos en Pinecone para sistemas RAG
Autor: Sistema de procesamiento de documentos
Fecha: 2025
"""

import os
import sys
import argparse
from typing import List, Dict
from dotenv import load_dotenv
import pdfplumber
from langchain.text_splitter import RecursiveCharacterTextSplitter
from openai import OpenAI
from pinecone import Pinecone, ServerlessSpec


def cargar_variables_entorno() -> Dict[str, str]:
    """
    Carga las variables de entorno necesarias desde el archivo .env
    
    Returns:
        Dict con las claves de API y configuraciones necesarias
    """
    print("üìã Cargando variables de entorno...")
    load_dotenv()
    
    # Validar que todas las variables necesarias est√©n presentes
    variables_requeridas = {
        'OPENAI_API_KEY': os.getenv('OPENAI_API_KEY'),
        'PINECONE_API_KEY': os.getenv('PINECONE_API_KEY'),
        'PINECONE_ENVIRONMENT': os.getenv('PINECONE_ENVIRONMENT'),
        'PINECONE_INDEX_NAME': os.getenv('PINECONE_INDEX_NAME')
    }
    
    # Verificar que todas las variables est√©n configuradas
    variables_faltantes = [k for k, v in variables_requeridas.items() if not v]
    if variables_faltantes:
        raise ValueError(f"‚ùå Variables de entorno faltantes: {', '.join(variables_faltantes)}")
    
    print("‚úÖ Variables de entorno cargadas correctamente")
    return variables_requeridas


def extraer_texto_pdf(ruta_pdf: str) -> str:
    """
    Extrae todo el texto de un archivo PDF usando pdfplumber
    
    Args:
        ruta_pdf: Ruta al archivo PDF a procesar
        
    Returns:
        String con todo el texto extra√≠do del PDF
    """
    print(f"üìÑ Abriendo archivo PDF: {ruta_pdf}")
    
    if not os.path.exists(ruta_pdf):
        raise FileNotFoundError(f"‚ùå El archivo no existe: {ruta_pdf}")
    
    texto_completo = ""
    
    try:
        with pdfplumber.open(ruta_pdf) as pdf:
            print(f"üìñ Procesando {len(pdf.pages)} p√°ginas...")
            
            for i, pagina in enumerate(pdf.pages, 1):
                texto_pagina = pagina.extract_text()
                if texto_pagina:
                    texto_completo += texto_pagina + "\n"
                
                # Mostrar progreso cada 10 p√°ginas
                if i % 10 == 0:
                    print(f"   Procesadas {i}/{len(pdf.pages)} p√°ginas...")
        
        print(f"‚úÖ Texto extra√≠do correctamente ({len(texto_completo)} caracteres)")
        return texto_completo
    
    except Exception as e:
        raise Exception(f"‚ùå Error al extraer texto del PDF: {str(e)}")


def dividir_texto_en_chunks(texto: str, chunk_size: int = 1000, chunk_overlap: int = 200) -> List[str]:
    """
    Divide el texto en fragmentos usando RecursiveCharacterTextSplitter
    
    Args:
        texto: Texto completo a dividir
        chunk_size: Tama√±o de cada fragmento en caracteres
        chunk_overlap: Superposici√≥n entre fragmentos en caracteres
        
    Returns:
        Lista de fragmentos de texto
    """
    print(f"‚úÇÔ∏è  Dividiendo texto en chunks (tama√±o: {chunk_size}, overlap: {chunk_overlap})...")
    
    try:
        # Inicializar el splitter con los par√°metros especificados
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=chunk_size,
            chunk_overlap=chunk_overlap,
            length_function=len,
            separators=["\n\n", "\n", " ", ""]
        )
        
        # Dividir el texto en chunks
        chunks = text_splitter.split_text(texto)
        
        print(f"‚úÖ Texto dividido en {len(chunks)} fragmentos")
        return chunks
    
    except Exception as e:
        raise Exception(f"‚ùå Error al dividir el texto: {str(e)}")


def generar_embeddings(chunks: List[str], api_key: str) -> List[List[float]]:
    """
    Genera embeddings para cada fragmento de texto usando OpenAI
    
    Args:
        chunks: Lista de fragmentos de texto
        api_key: Clave de API de OpenAI
        
    Returns:
        Lista de embeddings (vectores)
    """
    print(f"ü§ñ Generando embeddings para {len(chunks)} fragmentos...")
    
    try:
        # Inicializar cliente de OpenAI
        client = OpenAI(api_key=api_key)
        embeddings = []
        
        # Generar embeddings por lotes para optimizar
        batch_size = 100
        for i in range(0, len(chunks), batch_size):
            batch = chunks[i:i + batch_size]
            
            print(f"   Procesando fragmentos {i+1} a {min(i+batch_size, len(chunks))}...")
            
            # Llamar a la API de OpenAI para generar embeddings
            response = client.embeddings.create(
                model="text-embedding-3-small",  # Modelo recomendado por OpenAI
                input=batch
            )
            
            # Extraer los embeddings de la respuesta
            batch_embeddings = [item.embedding for item in response.data]
            embeddings.extend(batch_embeddings)
        
        print(f"‚úÖ Embeddings generados correctamente ({len(embeddings)} vectores)")
        return embeddings
    
    except Exception as e:
        raise Exception(f"‚ùå Error al generar embeddings: {str(e)}")


def subir_a_pinecone(
    chunks: List[str],
    embeddings: List[List[float]],
    api_key: str,
    environment: str,
    index_name: str,
    nombre_archivo: str
) -> None:
    """
    Sube los fragmentos y sus embeddings a Pinecone
    
    Args:
        chunks: Lista de fragmentos de texto
        embeddings: Lista de embeddings correspondientes
        api_key: Clave de API de Pinecone
        environment: Entorno de Pinecone
        index_name: Nombre del √≠ndice en Pinecone
        nombre_archivo: Nombre del archivo PDF original (para metadata)
    """
    print(f"üå≤ Conectando con Pinecone (√≠ndice: {index_name})...")
    
    try:
        # Inicializar cliente de Pinecone
        pc = Pinecone(api_key=api_key)
        
        # Verificar si el √≠ndice existe, si no, crearlo
        indices_existentes = [index.name for index in pc.list_indexes()]
        
        if index_name not in indices_existentes:
            print(f"‚ö†Ô∏è  El √≠ndice '{index_name}' no existe. Cre√°ndolo...")
            pc.create_index(
                name=index_name,
                dimension=len(embeddings[0]),  # Dimensi√≥n basada en el modelo de embeddings
                metric='cosine',
                spec=ServerlessSpec(
                    cloud='aws',
                    region=environment
                )
            )
            print(f"‚úÖ √çndice '{index_name}' creado correctamente")
        
        # Conectar al √≠ndice
        index = pc.Index(index_name)
        
        print(f"üì§ Subiendo {len(chunks)} vectores a Pinecone...")
        
        # Preparar los datos para upsert
        vectores_para_subir = []
        
        for i, (chunk, embedding) in enumerate(zip(chunks, embeddings)):
            # Crear un ID √∫nico para cada vector
            vector_id = f"{nombre_archivo}_chunk_{i}"
            
            # Preparar metadata
            metadata = {
                'text': chunk,
                'source': nombre_archivo,
                'chunk_id': i,
                'total_chunks': len(chunks)
            }
            
            # Agregar a la lista
            vectores_para_subir.append({
                'id': vector_id,
                'values': embedding,
                'metadata': metadata
            })
        
        # Hacer upsert por lotes (Pinecone recomienda lotes de 100)
        batch_size = 100
        for i in range(0, len(vectores_para_subir), batch_size):
            batch = vectores_para_subir[i:i + batch_size]
            index.upsert(vectors=batch)
            
            print(f"   Subidos {min(i+batch_size, len(vectores_para_subir))}/{len(vectores_para_subir)} vectores...")
        
        # Verificar estad√≠sticas del √≠ndice
        stats = index.describe_index_stats()
        print(f"‚úÖ Datos subidos correctamente a Pinecone")
        print(f"üìä Total de vectores en el √≠ndice: {stats.total_vector_count}")
    
    except Exception as e:
        raise Exception(f"‚ùå Error al subir datos a Pinecone: {str(e)}")


def main():
    """
    Funci√≥n principal que orquesta todo el proceso
    """
    print("=" * 60)
    print("üöÄ PROCESADOR DE PDFs PARA SISTEMA RAG")
    print("=" * 60)
    print()
    
    # Configurar argumentos de l√≠nea de comandos
    parser = argparse.ArgumentParser(
        description='Procesa un archivo PDF y lo carga en Pinecone para RAG'
    )
    parser.add_argument(
        'pdf_path',
        type=str,
        help='Ruta al archivo PDF a procesar'
    )
    parser.add_argument(
        '--chunk-size',
        type=int,
        default=1000,
        help='Tama√±o de cada fragmento en caracteres (default: 1000)'
    )
    parser.add_argument(
        '--chunk-overlap',
        type=int,
        default=200,
        help='Superposici√≥n entre fragmentos en caracteres (default: 200)'
    )
    
    args = parser.parse_args()
    
    try:
        # Paso 1: Cargar variables de entorno
        variables = cargar_variables_entorno()
        print()
        
        # Paso 2: Extraer texto del PDF
        texto = extraer_texto_pdf(args.pdf_path)
        print()
        
        # Validar que se extrajo texto
        if not texto.strip():
            raise ValueError("‚ùå No se pudo extraer texto del PDF. El archivo puede estar vac√≠o o corrupto.")
        
        # Paso 3: Dividir texto en chunks
        chunks = dividir_texto_en_chunks(texto, args.chunk_size, args.chunk_overlap)
        print()
        
        # Paso 4: Generar embeddings
        embeddings = generar_embeddings(chunks, variables['OPENAI_API_KEY'])
        print()
        
        # Paso 5 y 6: Conectar y subir a Pinecone
        nombre_archivo = os.path.basename(args.pdf_path)
        subir_a_pinecone(
            chunks=chunks,
            embeddings=embeddings,
            api_key=variables['PINECONE_API_KEY'],
            environment=variables['PINECONE_ENVIRONMENT'],
            index_name=variables['PINECONE_INDEX_NAME'],
            nombre_archivo=nombre_archivo
        )
        print()
        
        # Resumen final
        print("=" * 60)
        print("‚ú® PROCESO COMPLETADO EXITOSAMENTE")
        print("=" * 60)
        print(f"üìÑ Archivo procesado: {nombre_archivo}")
        print(f"üìä Total de fragmentos: {len(chunks)}")
        print(f"ü§ñ Embeddings generados: {len(embeddings)}")
        print(f"üå≤ √çndice Pinecone: {variables['PINECONE_INDEX_NAME']}")
        print("=" * 60)
    
    except FileNotFoundError as e:
        print(f"\n‚ùå ERROR: {str(e)}")
        sys.exit(1)
    
    except ValueError as e:
        print(f"\n‚ùå ERROR: {str(e)}")
        sys.exit(1)
    
    except Exception as e:
        print(f"\n‚ùå ERROR INESPERADO: {str(e)}")
        print("Por favor, verifica tu configuraci√≥n y vuelve a intentarlo.")
        sys.exit(1)


if __name__ == "__main__":
    main()
